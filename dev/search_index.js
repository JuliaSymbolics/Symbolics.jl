var documenterSearchIndex = {"docs":
[{"location":"manual/ode/#Symbolic-ODE-Solving","page":"Symbolic ODE Solving","title":"Symbolic ODE Solving","text":"While not all ODEs have an analytical solution, symbolic ODE solving is provided by Symbolics.jl for  subsets of cases for which known analytical solutions can be obtained. These expressions can then be merged with other techniques in order to accelerate code or gain a deeper understanding of real-world systems.","category":"section"},{"location":"manual/ode/#Merging-Symbolic-ODEs-with-Numerical-Methods:-ModelingToolkit.jl","page":"Symbolic ODE Solving","title":"Merging Symbolic ODEs with Numerical Methods: ModelingToolkit.jl","text":"If you are looking to merge Symbolics.jl manipulations with numerical solvers such as DifferentialEquations.jl, then we highly recommend checking out the ModelingToolkit.jl system. It represents systems of differentible-algebraic equations (DAEs, and extension to ODEs) for which a sophisticated symbolic analysis pipeline is used to generate highly efficient code. This mtkcompile pipeline makes use of all tricks from Symbolics.jl and many that are more specific to numerical code generation, such as Pantelides index reduction and tearing of nonlinear systems, and it will analytically solve subsets of the ODE system as finds possible. Thus if you are attempting to use Symbolics to pre-solve some parts of an ODE analytically, we recommend allowing ModelingToolkit.jl to do this optimization.\n\nNote that if ModelingToolkit is able to analytically solve the equation, it will give an ODEProblem where prob.u0 === nothing, and then running solve on the ODEProblem will give a numerical ODESolution object that on-demand uses the analytical solution to generate any plots or other artifacts. The analytical solution can be investigated symbolically using observed(sys).","category":"section"},{"location":"manual/ode/#Symbolically-Solving-ODEs","page":"Symbolic ODE Solving","title":"Symbolically Solving ODEs","text":"note: Note\nThis area is currently under heavy development. More solvers will be available in the near future.","category":"section"},{"location":"manual/ode/#SymPy","page":"Symbolic ODE Solving","title":"SymPy","text":"","category":"section"},{"location":"manual/ode/#Symbolics.SymbolicLinearODE","page":"Symbolic ODE Solving","title":"Symbolics.SymbolicLinearODE","text":"Represents a linear ordinary differential equation of the form:\n\ndⁿx/dtⁿ + pₙ(t)(dⁿ⁻¹x/dtⁿ⁻¹) + ... + p₂(t)(dx/dt) + p₁(t)x = q(t)\n\nFields\n\nx: dependent variable\nt: independent variable\np: coefficient functions of t ordered in increasing order (p₁, p₂, ...)\nq: right hand side function of t, without any x\n\nExamples\n\njulia> using Symbolics\n\njulia> @variables x, t\n2-element Vector{Num}:\n x\n t\n\njulia> eq = SymbolicLinearODE(x, t, [1, 2, 3], 3exp(4t))\n(Dt^3)x + (3)(Dt^2)x + (2)(Dt^1)x + (1)(Dt^0)x ~ 3exp(4t)\n\n\n\n\n\n","category":"type"},{"location":"manual/ode/#Symbolics.symbolic_solve_ode","page":"Symbolic ODE Solving","title":"Symbolics.symbolic_solve_ode","text":"symbolic_solve_ode(eq::SymbolicLinearODE)\n\nSymbolically solve a linear ordinary differential equation\n\nArguments\n\neq: a SymbolicLinearODE to solve\n\nReturns\n\nSymbolic solution to the ODE\n\nSupported Methods\n\nfirst-order integrating factor\nconstant coefficient homogeneous solutions (can handle repeated and complex characteristic roots)\nexponential and resonant response formula particular solutions (for any linear combination of exp, sin, cos, or exp times sin or cos (e.g. e^2t * cos(-t) + e^-3t + sin(5t)))\nmethod of undetermined coefficients particular solutions\nlinear combinations of above particular solutions\n\nExamples\n\njulia> using Symbolics; import Nemo, SymPy\n\njulia> @variables x, t\n2-element Vector{Num}:\n x\n t\n\n# Integrating Factor (note that SymPy is required for integration)\njulia> symbolic_solve_ode(SymbolicLinearODE(x, t, [5/t], 7t))\n(C₁ + t^7) / (t^5)\n\n# Constant Coefficients and RRF (note that Nemo is required to find characteristic roots)\njulia> symbolic_solve_ode(SymbolicLinearODE(x, t, [9, -6], 4exp(3t)))\nC₁*exp(3t) + C₂*t*exp(3t) + (2//1)*(t^2)*exp(3t)\n\njulia> symbolic_solve_ode(SymbolicLinearODE(x, t, [6, 5], 2exp(-t)*cos(t)))\nC₁*exp(-2t) + C₂*exp(-3t) + (1//5)*cos(t)*exp(-t) + (3//5)*exp(-t)*sin(t)\n\n# Method of Undetermined Coefficients\njulia> symbolic_solve_ode(SymbolicLinearODE(x, t, [-3, 2], 2t - 5))\n(11//9) - (2//3)*t + C₁*exp(t) + C₂*exp(-3t)\n\n\n\n\n\nsymbolic_solve_ode(expr::Equation, x, t)\n\nSymbolically solve an ODE\n\nArguments\n\nexpr: a symbolic ODE\nx: dependent variable\nt: independent variable\n\nSupported Methods\n\nall methods of solving linear ODEs mentioned for symbolic_solve_ode(eq::SymbolicLinearODE)\nClairaut's equation\nBernoulli equations\n\nExamples\n\njulia> using Symbolics; import Nemo, SymPy\n\njulia> @variables x, t\n2-element Vector{Num}:\n x\n t\n\njulia> Dt = Differential(t)\nDifferential(t)\n\n# SymbolicLinearODE (via constant coefficients and RRF)\njulia> symbolic_solve_ode(9t*x - 6*Dt(x) ~ 4exp(3t), x, t)\nC₁*exp(3t) + C₂*t*exp(3t) + (2//1)*(t^2)*exp(3t)\n\n# Clairaut's equation\njulia> symbolic_solve_ode(x ~ Dt(x)*t - ((Dt(x))^3), x, t)\nC₁*t - (C₁^3)\n\n# Bernoulli equations\njulia> symbolic_solve_ode(Dt(x) + (4//t)*x ~ t^3 * x^2, x, t)\n1 / (C₁*(t^4) - (t^4)*log(t))\n\n\n\n\n\n","category":"function"},{"location":"manual/ode/#Symbolics.solve_symbolic_IVP","page":"Symbolic ODE Solving","title":"Symbolics.solve_symbolic_IVP","text":"solve_symbolic_IVP(eq::SymbolicLinearODE, initial_conditions::Vector{<:Number})\n\nSolve an initial value problem for a linear ODE with given initial conditions.\n\nArguments\n\neq: A SymbolicLinearODE to solve\ninitial_conditions: Vector of initial conditions for x(0), x'(0), x''(0), etc.\n\nReturns\n\nSymbolic solution satisfying the initial conditions\n\nExamples\n\njulia> using Symbolics\njulia> @variables x, t\n2-element Vector{Num}:\n x\n t\n\njulia> eq = SymbolicLinearODE(x, t, [-3, 2], 0)  # d²x/dt² + 2dx/dt - 3x = 0\njulia> solve_symbolic_IVP(eq, [1, -1])  # x(0) = 1, x'(0) = -1\n(1//2)*exp(-3t) + (1//2)*exp(t)\n\n\n\n\n\n","category":"function"},{"location":"manual/ode/#Symbolics.solve_linear_ode_system","page":"Symbolic ODE Solving","title":"Symbolics.solve_linear_ode_system","text":"solve_linear_ode_system(A::Matrix{<:Number}, x0::Vector{<:Number}, t::Num)\n\nSolve linear continuous dynamical system of differential equations of the form Ax = x' with initial condition x0\n\nArguments\n\nA: matrix of coefficients\nx0: initial conditions vector\nt: independent variable\n\nReturns\n\nvector of symbolic solutions\n\nExamples\n\n!!! note uses method symbolic_solve, so packages Nemo and Groebner are often required\n\njulia> @variables t\n1-element Vector{Num}:\n t\n\njulia> solve_linear_ode_system([1 0; 0 -1], [1, -1], t) # requires Nemo\n2-element Vector{Num}:\n   exp(t)\n -exp(-t)\n\njulia> solve_linear_ode_system([-3 4; -2 3], [7, 2], t) # requires Groebner\n2-element Vector{Num}:\n (10//1)*exp(-t) - (3//1)*exp(t)\n  (5//1)*exp(-t) - (3//1)*exp(t)\n\n\n\n\n\n","category":"function"},{"location":"manual/ode/#Symbolics.sympy_ode_solve","page":"Symbolic ODE Solving","title":"Symbolics.sympy_ode_solve","text":"sympy_ode_solve(expr, func, var)\n\nSolves ODE expr = 0 for function func w.r.t. var using SymPy.\n\nArguments\n\nexpr: Symbolics expression representing ODE (set to 0).\nfunc: Symbolics function (e.g., f(x)).\nvar: Independent Symbolics variable.\n\nReturns\n\nSymbolics solution(s).\n\nExample\n\n@variables x\n@syms f(x)\nexpr = Symbolics.Derivative(f, x) - 2*f\nsol = sympy_ode_solve(expr, f, x)  # Returns C1*exp(2*x)\n\n\n\n\n\n","category":"function"},{"location":"manual/ode/#Symbolics.sympy_pythoncall_ode_solve","page":"Symbolic ODE Solving","title":"Symbolics.sympy_pythoncall_ode_solve","text":"sympy_pythoncall_ode_solve(expr, func, var)\n\nSolves ordinary differential equations using SymPyPythonCall.\n\nArguments\n\nexpr: Symbolics expression representing the ODE.\nfunc: Function to solve for.\nvar: Independent variable.\n\nReturns\n\nSymbolics solution(s).\n\nExample\n\n@variables x\n@syms f(x)\nexpr = Symbolics.Derivative(f, x) - 2*f\nsol = sympy_pythoncall_ode_solve(expr, f, x)  # Returns C1*exp(2*x)\n\n\n\n\n\n","category":"function"},{"location":"manual/faq/#Frequently-Asked-Questions","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"","category":"section"},{"location":"manual/faq/#Limits-of-Symbolic-Computation","page":"Frequently Asked Questions","title":"Limits of Symbolic Computation","text":"","category":"section"},{"location":"manual/faq/#Transforming-my-function-to-a-symbolic-equation-has-failed.-What-do-I-do?","page":"Frequently Asked Questions","title":"Transforming my function to a symbolic equation has failed. What do I do?","text":"If you see the error:\n\nERROR: TypeError: non-boolean (Num) used in boolean context\n\nthis is likely coming from an algorithm which cannot be traced into a purely symbolic algorithm. Many numerical solvers, for instance, have this property. It shows up when you're doing something like if x < tol. If x is a number, then this is true or false. If x is a symbol, then it's x < tol, so Julia just cannot know how many iterations to do and throws an error.\n\nThis shows up in adaptive algorithms, for example:\n\nfunction factorial(x)\n  out = x\n  while x > 1\n    x -= 1\n    out *= x\n  end\n  out\nend\n\nThe number of iterations this algorithm runs for is dependent on the value of x, and so there is no static representation of the algorithm. If x is 5, then it's out = x*(x-1)*(x-2)*(x-3)*(x-4), while if x is 3, then it's out = x*(x-1)*(x-2). It should thus be no surprise that:\n\nusing Symbolics\n@variables x\ntry\n    factorial(x)\ncatch e\n    e\nend\n\nfails. It's not that there is anything wrong with this code, but it's not going to work because fundamentally this is not a symbolically-representable algorithm.\n\nThe space of algorithms which can be turned into symbolic algorithms is what we call quasi-static, that is, there is a way to represent the algorithm as static. Loops are allowed, but the amount of loop iterations should not require that you know the value of the symbol x. If the algorithm is quasi-static, then Symbolics.jl tracing will produce the static form of the code, unrolling the operations, and generating a flat representation of the algorithm.","category":"section"},{"location":"manual/faq/#What-can-be-done?","page":"Frequently Asked Questions","title":"What can be done?","text":"If you need to represent this function f symbolically, then you'll need to make sure it's not traced and instead is directly represented in the underlying computational graph. Just like how sqrt(x) symbolically does not try to represent the underlying algorithm, this must be done to your f. This is done by doing @register_symbolic f(x). If you have to define things like derivatives to f, then the function registration documentation.","category":"section"},{"location":"manual/faq/#Equality-and-set-membership-tests","page":"Frequently Asked Questions","title":"Equality and set membership tests","text":"Comparing symbols with == produces a symbolic equality, not a Bool. To produce a Bool, call isequal.\n\nTo test if a symbol is part of a collection of symbols, i.e., a vector, either create a Set and use in, e.g.\n\ntry \n    x in [x]\ncatch e\n    e\nend\n\nx in Set([x])\n\nany(isequal(x), [x])\n\nIf == is used instead, you will receive TypeError: non-boolean (Num) used in boolean context. What this error  is telling you is that the symbolic x == y expression is being used where a Bool is required, such as if x == y, and since the symbolic expression is held lazily this will error because the appropriate branch cannot be selected (since x == y is unknown for arbitrary symbolic values!). This is why the check isequal(x,y) is required, since this is a non-lazy check of whether the symbol x is always equal to the symbol y, rather than an expression of whether x and y currently have the same value.","category":"section"},{"location":"manual/faq/#Understanding-the-Difference-Between-the-Julia-Variable-and-the-Symbolic-Variable","page":"Frequently Asked Questions","title":"Understanding the Difference Between the Julia Variable and the Symbolic Variable","text":"In the most basic usage of Symbolics, the name of the Julia variable and the symbolic variable are the same. For example, when we do:\n\n@variables a\n\nthe name of the symbolic variable is a and same with the Julia variable. However, we can de-couple these by setting a to a new symbolic variable, for example:\n\nb = only(@variables(a))\n\nNow the Julia variable b refers to the variable named a. However, the downside of this current approach is that it requires that the user writing the script knows the name a that they want to place to the variable. But what if for example we needed to get the variable's name from a file?\n\nTo do this, one can interpolate a symbol into the @variables macro using $. For example:\n\na = :c\nb = only(@variables($a))\n\nIn this example, @variables($a) created a variable named c, and set this variable to b.","category":"section"},{"location":"comparison/#Comparison-of-Julia's-Symbolics.jl-vs-SymPy-for-Symbolic-Computation","page":"Comparison Against SymPy","title":"Comparison of Julia's Symbolics.jl vs SymPy for Symbolic Computation","text":"Symbolics.jl is a symbolic modeling language for Julia, built in Julia. Its goal is very different from Sympy: it was made to support symbolic-numerics, the combination of symbolic computing with numerical methods to allow for extreme performance computing that would not be possible without modifying the model. Because of this, Symbolics.jl excels in many areas due to purposeful design decisions:\n\nPerformance: Symbolics.jl is built in Julia, whereas SymPy was built in Python. Thus, the performance bar for Symbolics.jl is much higher. Symbolics.jl started because SymPy was far too slow and SymEngine was far too inflexible for the projects they were doing. Performance is key to Symbolics.jl. If you find any performance issues, please file an issue.\nbuild_function: lambdify is “fine” for some people, but if you're building a super fast MPI-enabled Julia/C/Fortran simulation code, having a function that hits the Python interpreter is less than optimal. By default, build_function builds fast JIT-compiled functions due to being in Julia. However, it has support for things like static arrays, non-allocating functions via mutation, fast functions on sparse matrices and arrays of arrays, etc.: all core details of doing high performance computing.\nParallelism: Symbolics.jl has pervasive parallelism. The symbolic simplification via SymbolicUtils.jl has built-in parallelism, Symbolics.jl builds functions that parallelize across threads. Symbolics.jl is compatible with GPU libraries like CUDA.jl.\nExtensible: Symbolics.jl and its underlying tools are written in pure Julia. Want to add new or better simplification rules? Add some Julia code! Need to add new derivatives? Add some Julia code! You get the picture. Breaking down these barriers makes it easier for the user to tailor the program to their needs and accelerates the development of the library.\nDeep integration with the Julia ecosystem: Symbolics.jl's integration with neural networks is not the only thing that's deep. Symbolics.jl is built with the same philosophy as other SciML packages, eschewing “monorepos” for a distributed development approach that ties together the work of many developers. The differentiation parts utilize tools from automatic differentiation libraries, all linear algebra functionality comes from tracing Julia Base itself, symbolic rewriting (simplification and substitution) comes from SymbolicUtils.jl, parallelism comes from Julia Base libraries, Dagger.jl, etc. SciML Tools like DataDrivenDiffEq.jl can reconstruct symbolic expressions from neural networks and data, while NeuralPDE.jl can automatically solve partial differential equations from symbolic descriptions using physics-informed neural networks. The list keeps going. All told, by design Symbolics.jl's development moves fast because it's effectively using the work of hundreds of Julia developers, allowing it to grow fast.\nWhile Symbolics.jl has many features missing from SymPy, it does not superset SymPy's functionality. For a list of missing features, see this issue.","category":"section"},{"location":"manual/constraint_satisfaction/#Constraint-Satisfaction","page":"Constraint Satisfaction","title":"Constraint Satisfaction","text":"Symbolic constraint satisfaction is a powerful technique for solving problems where you need to find values for symbolic variables that satisfy a set of constraints. Symbolics.jl provides constraint satisfaction capabilities through integration with SAT solvers and theorem provers.\n\nnote: Note\nConstraint satisfaction in symbolic computation is an active area of research. The available tools provide experimental functionality that continues to evolve.","category":"section"},{"location":"manual/constraint_satisfaction/#What-is-Constraint-Satisfaction?","page":"Constraint Satisfaction","title":"What is Constraint Satisfaction?","text":"A Constraint Satisfaction Problem (CSP) consists of:\n\nA set of variables\nA domain for each variable (the possible values it can take)\nA set of constraints that define relationships between variables\n\nThe goal is to find an assignment of values to variables that satisfies all constraints simultaneously.\n\nIn symbolic computation, constraint satisfaction extends beyond simple numerical domains to handle symbolic expressions, boolean formulas, and mathematical relationships.","category":"section"},{"location":"manual/constraint_satisfaction/#SymbolicSMT.jl","page":"Constraint Satisfaction","title":"SymbolicSMT.jl","text":"SymbolicSMT.jl extends SymbolicUtils expression simplification with theorem proving capabilities through the Z3 Theorem Prover. It allows adding boolean constraints to the symbolic simplification process.","category":"section"},{"location":"manual/constraint_satisfaction/#Key-Features","page":"Constraint Satisfaction","title":"Key Features","text":"Z3 Integration: Uses the powerful Z3 SMT (Satisfiability Modulo Theories) solver\nSymbolic Constraints: Work with symbolic mathematical expressions as constraints\nSatisfiability Checking: Determine if expressions can be satisfied under constraints\nProvability Checking: Prove or disprove statements under constraints\nBoolean Logic: Handle complex boolean formulas and logical relationships","category":"section"},{"location":"manual/constraint_satisfaction/#Basic-Usage","page":"Constraint Satisfaction","title":"Basic Usage","text":"using Symbolics, SymbolicSMT\n\n@variables x::Real y::Real\n\n# Define constraints\nconstraints = Constraints([x > 0, y > 0])\n\n# Check if an expression is satisfiable under constraints\nissatisfiable(x + y > 1, constraints)\n\n# Check if an expression is provable (always true) under constraints\nisprovable(x >= 0, constraints)\n\n# Check if x can be negative (it cannot, given x > 0)\nissatisfiable(x < 0, constraints)","category":"section"},{"location":"manual/constraint_satisfaction/#Example-Applications","page":"Constraint Satisfaction","title":"Example Applications","text":"","category":"section"},{"location":"manual/constraint_satisfaction/#Bound-Checking","page":"Constraint Satisfaction","title":"Bound Checking","text":"@variables a::Integer b::Integer\n\n# Define bounds\nbounds = Constraints([a >= 0, a <= 10, b >= 0, b <= 10])\n\n# Can the sum exceed 15?\nissatisfiable(a + b > 15, bounds)\n\n# Is the sum always at most 20?\nisprovable(a + b <= 20, bounds)","category":"section"},{"location":"manual/constraint_satisfaction/#Quadratic-Constraints","page":"Constraint Satisfaction","title":"Quadratic Constraints","text":"@variables p::Integer q::Integer\n\n# Circle-like constraint\ncircle = Constraints([p^2 + q^2 < 25])\n\n# Can p be 3?\nissatisfiable(p == 3, circle)\n\n# Can p be 5? (No, because 5^2 = 25 is not < 25)\nissatisfiable(p == 5, circle)","category":"section"},{"location":"manual/constraint_satisfaction/#SAT-Solving-in-Julia","page":"Constraint Satisfaction","title":"SAT Solving in Julia","text":"","category":"section"},{"location":"manual/constraint_satisfaction/#What-is-SAT?","page":"Constraint Satisfaction","title":"What is SAT?","text":"Boolean Satisfiability Testing (SAT) is the problem of determining whether there exists an assignment of truth values to boolean variables that makes a given boolean formula evaluate to true. SAT is fundamental to many computational problems and is NP-complete.","category":"section"},{"location":"manual/constraint_satisfaction/#Applications-of-SAT-Solvers","page":"Constraint Satisfaction","title":"Applications of SAT Solvers","text":"SAT solvers have wide applications in:\n\nSoftware Verification: Model checking, program analysis\nHardware Verification: Circuit verification and testing\nPlanning and Scheduling: Resource allocation, job scheduling\nArtificial Intelligence: Automated reasoning, knowledge representation\nCryptography: Cryptanalysis and security analysis\nOperations Research: Optimization problems\nCombinatorial Problems: Sudoku, graph coloring, constraint puzzles","category":"section"},{"location":"manual/constraint_satisfaction/#SAT-in-Symbolic-Computation","page":"Constraint Satisfaction","title":"SAT in Symbolic Computation","text":"In symbolic computation, SAT solvers enable:\n\nConstraint Solving: Finding symbolic solutions to constraint systems\nTheorem Proving: Automatically proving or disproving mathematical statements\nExpression Simplification: Simplifying expressions under logical constraints\nSatisfiability Checking: Determining if constraint systems have solutions","category":"section"},{"location":"manual/constraint_satisfaction/#Boolean-Constraints","page":"Constraint Satisfaction","title":"Boolean Constraints","text":"@variables flag1::Bool flag2::Bool\n\n# Boolean constraints\nbool_constraints = Constraints([flag1, flag2])\n\n# Both flags are true, so their AND is satisfiable\nissatisfiable(flag1 & flag2, bool_constraints)\n\n# Can flag1 be false? No, it's constrained to be true\nissatisfiable(!flag1, bool_constraints)","category":"section"},{"location":"manual/constraint_satisfaction/#SMT-Solvers","page":"Constraint Satisfaction","title":"SMT Solvers","text":"Satisfiability Modulo Theories (SMT) solvers extend SAT solvers to handle richer mathematical structures:\n\nArithmetic: Integer and real number constraints\nArrays: Array indexing and element constraints\nBit-vectors: Fixed-width integer arithmetic\nStrings: String manipulation and pattern matching\nAlgebraic Data Types: Custom mathematical structures","category":"section"},{"location":"manual/constraint_satisfaction/#Z3-Theorem-Prover","page":"Constraint Satisfaction","title":"Z3 Theorem Prover","text":"Z3 is Microsoft Research's high-performance SMT solver that SymbolicSMT.jl uses:\n\nMultiple Theories: Supports arithmetic, bit-vectors, arrays, and more\nDecision Procedures: Efficient algorithms for theory-specific reasoning\nModel Generation: Can provide example solutions when constraints are satisfiable\nProof Generation: Can generate proofs of unsatisfiability","category":"section"},{"location":"manual/constraint_satisfaction/#Advanced-Constraint-Satisfaction","page":"Constraint Satisfaction","title":"Advanced Constraint Satisfaction","text":"","category":"section"},{"location":"manual/constraint_satisfaction/#Multi-Variable-Arithmetic","page":"Constraint Satisfaction","title":"Multi-Variable Arithmetic","text":"SymbolicSMT.jl supports multi-variable arithmetic expressions:\n\n@variables m::Integer n::Integer\n\n# Multi-variable constraints\nmulti_constraints = Constraints([m >= 1, n >= 1])\n\n# Check multi-variable expressions - can sum be <= 0?\nissatisfiable(m + n <= 0, multi_constraints)  # false - m + n >= 2 when m,n >= 1\n\n# Is sum always >= 2?\nisprovable(m + n >= 2, multi_constraints)  # true - always satisfied when m,n >= 1","category":"section"},{"location":"manual/constraint_satisfaction/#Power-Operators","page":"Constraint Satisfaction","title":"Power Operators","text":"@variables t::Integer\n\npower_constraints = Constraints([t >= 0, t <= 3])\n\n# Can t^2 be at most 9?\nissatisfiable(t^2 <= 9, power_constraints)\n\n# Is t^2 always <= 9 when t is in [0,3]?\nisprovable(t^2 <= 9, power_constraints)","category":"section"},{"location":"manual/constraint_satisfaction/#Expression-Resolution","page":"Constraint Satisfaction","title":"Expression Resolution","text":"The resolve function attempts to determine if an expression is provably true or false:\n\n@variables v::Integer\n\nresolve_constraints = Constraints([v > 5])\n\n# v > 0 is provably true when v > 5\nresolve(v > 0, resolve_constraints)\n\n# v < 0 is provably false when v > 5\nresolve(v < 0, resolve_constraints)\n\n# v > 10 cannot be determined - returns the expression\nresolve(v > 10, resolve_constraints)","category":"section"},{"location":"manual/constraint_satisfaction/#Integration-with-Symbolic-Computation","page":"Constraint Satisfaction","title":"Integration with Symbolic Computation","text":"Constraint satisfaction integrates naturally with other symbolic computation features:\n\nSymbolic Differentiation: Optimize constraint systems using gradients\nSymbolic Integration: Handle constraints involving integrals\nExpression Manipulation: Simplify complex constraint expressions\nCode Generation: Generate efficient constraint checking code","category":"section"},{"location":"manual/constraint_satisfaction/#Further-Reading","page":"Constraint Satisfaction","title":"Further Reading","text":"SymbolicSMT.jl Repository\nZ3 Theorem Prover\nSatisfiability.jl - Alternative SAT interface for Julia\nSMT-LIB Standard - Standard format for SMT solvers","category":"section"},{"location":"manual/groebner/#Groebner-bases","page":"Groebner bases","title":"Groebner bases","text":"Groebner bases use the implementation of the F4 algorithm from  Groebner.jl package as its backend. We refer to the documentation of Groebner.jl, which lists some implementations details and possible use-cases of Groebner bases.","category":"section"},{"location":"tutorials/perturbation/#perturb_alg","page":"Mixed Symbolic-Numeric Perturbation Theory","title":"Mixed Symbolic-Numeric Perturbation Theory","text":"Symbolics.jl is a fast and modern Computer Algebra System (CAS) written in Julia. It is an integral part of the SciML ecosystem of differential equation solvers and scientific machine learning packages. While Symbolics.jl is primarily designed for modern scientific computing (e.g. automatic differentiation and machine learning), it is also a powerful CAS that can be used for classic scientific computing. One such application is using perturbation theory to solve algebraic and differential equations.\n\nPerturbation methods are a collection of techniques to solve hard problems that generally don't have a closed solution, but depend on a tunable parameter and have closed or easy solutions for some values of this parameter. The main idea is to assume a solution that is a power series in the tunable parameter (say ϵ), such that ϵ = 0 corresponds to an easy solution, and then solve iteratively for higher-order corrections.\n\nThe hallmark of perturbation theory is the generation of long and convoluted intermediate equations by this process. These are subjected to algorithmic and mechanical manipulations, which makes perturbation methods an excellent fit for a CAS. In fact, CAS software have been used for perturbation calculations since the early 1970s.\n\nThis tutorial shows how to mix symbolic manipulations and numerical methods to solve algebraic equations with perturbation theory. Another tutorial applies it to differential equations.","category":"section"},{"location":"tutorials/perturbation/#Solving-the-quintic-equation","page":"Mixed Symbolic-Numeric Perturbation Theory","title":"Solving the quintic equation","text":"The “hello world!” analog of perturbation problems is to find a real solution x to the quintic (fifth-order) equation\n\nusing Symbolics\n@variables x\nquintic = x^5 + x ~ 1\n\nAccording to Abel's theorem, a general quintic equation does not have a closed form solution. But we can easily solve it numerically using Newton's method (here implemented for simplicity, and not performance):\n\nfunction solve_newton(eq, x, x₀; abstol=1e-8, maxiters=50)\n    # symbolic expressions for f(x) and f′(x)\n    f = eq.lhs - eq.rhs # want to find root of f(x)\n    f′ = Symbolics.derivative(f, x)\n\n    xₙ = x₀ # numerical value of the initial guess\n    for i = 1:maxiters\n        # calculate new guess by numerically evaluating symbolic expression at previous guess\n        xₙ₊₁ = Symbolics.value(substitute(x - f / f′, x => xₙ; fold = Val(true)))\n        if abs(xₙ₊₁ - xₙ) < abstol\n            return xₙ₊₁ # converged\n        else\n            xₙ = xₙ₊₁\n        end\n    end\n    error(\"Newton's method failed to converge\")\nend\n\nx_newton = solve_newton(quintic, x, 1.0)\nprintln(\"Newton's method solution: x = \", x_newton)\n\nTo solve the same problem with perturbation theory, we must introduce an expansion variable ϵ in the equation:\n\n@variables ϵ # expansion variable\nquintic = x^5 + ϵ*x ~ 1\n\nIf ϵ = 1, we get our original problem. With ϵ = 0, the problem transforms to the easy quintic equation x^5 = 1 with the trivial real solution x = 1 (and four complex solutions which we ignore). Next, expand x as a power series in ϵ:\n\nx_coeffs, = @variables a[0:7] # create Taylor series coefficients\nx_taylor = series(x_coeffs, ϵ) # expand x in a power series in ϵ\n\nThen insert this into the quintic equation and expand it, too, to the same order:\n\nquintic_taylor = substitute(quintic, x => x_taylor)\nquintic_taylor = taylor(quintic_taylor, ϵ, 0:7)\n\nThis messy equation must hold for each power of ϵ, so we can separate it into one nicer equation per order:\n\nquintic_eqs = taylor_coeff(quintic_taylor, ϵ, 0:7)\nquintic_eqs[1:5] # for readability, show only 5 shortest equations\n\nThese equations show three important features of perturbation theory:\n\nThe 0-th order equation is trivial in x_0: here x_0^5 = 1 has the trivial real solution x_0 = 1.\nThe n-th order equation is linear in x_n (except the trivial 0-th order equation).\nThe equations are triangular in x_n: the n-th order equation can be solved for x_n given only x_m for mn.\n\nThis structure is what makes the perturbation theory so attractive: we can start with the trivial solution x_0 = 1, then linearly solve for x_n order-by-order and substitute in the solutions of x_m for mn obtained so far.\n\nHere is a simple function that uses this cascading strategy to solve such a set of equations eqs for the variables xs, given a solution x₀ of the first equation eqs[begin]:\n\nfunction solve_cascade(eqs, xs, x₀, ϵ)\n    sol = Dict(xs[begin] => x₀) # store solutions in a map\n\n    # verify that x₀ is a solution of the first equation\n    eq0 = substitute(eqs[1], sol; fold = Val(true))\n    isequal(eq0.lhs, eq0.rhs) || error(\"$sol does not solve $(eqs[1])\")\n\n    # solve remaining equations sequentially\n    for i in 2:length(eqs)\n        eq = substitute(eqs[i], sol) # insert previous solutions\n        x = xs[begin+i-1] # need not be 1-indexed\n        xsol = Symbolics.symbolic_linear_solve(eq, x) # solve current equation\n        sol = merge(sol, Dict(x => xsol)) # store solution\n    end\n\n    return sol\nend\n\nLet us solve our order-separated quintics for the coefficients, and substitute them into the full series for x:\n\nx_coeffs_sol = solve_cascade(quintic_eqs, x_coeffs, 1, ϵ)\nx_pert = substitute(x_taylor, x_coeffs_sol)\n\nThe n-th order solution of our original quintic equation is the sum up to the ϵ^n-th order term, evaluated at ϵ=1:\n\nfor n in 0:7\n    x_pert_sol = substitute(taylor(x_pert, ϵ, 0:n), ϵ => big(1))\n    println(\"$n-th order solution: x = $x_pert_sol = $(x_pert_sol * 1.0)\")\nend\n\nThis is close to the solution from Newton's method!","category":"section"},{"location":"tutorials/perturbation/#Solving-Kepler's-Equation","page":"Mixed Symbolic-Numeric Perturbation Theory","title":"Solving Kepler's Equation","text":"Historically, perturbation methods were first invented to calculate orbits of the Moon and the planets. In homage to this history, our second example is to solve Kepler's equation, which is central to solving two-body Keplerian orbits:\n\n@variables e E M\nkepler = E - e * sin(E) ~ M\n\nWe want to solve for the eccentric anomaly E given the eccentricity e and mean anomaly M. This is also easy with Newton's method. With Earth's eccentricity e = 001671 and M = pi2:\n\nvals_earth = Dict(e => 0.01671, M => π/2)\nE_newton = solve_newton(substitute(kepler, vals_earth), E, π/2)\nprintln(\"Newton's method solution: E = \", E_newton)\n\nNext, let us solve the same problem with the perturbative method. It is most common to expand E as a series in M. Repeating the procedure from the quintic example, we get these equations:\n\nE_taylor = series(E, M, 0:5) # this auto-creates coefficients E[0:5]\nE_coeffs = taylor_coeff(E_taylor, M) # get a handle to the coefficients\nkepler_eqs = taylor_coeff(substitute(kepler, E => E_taylor), M, 0:5)\nkepler_eqs[1:4] # for readability\n\nThe trivial 0-th order solution (when M=0) is E_0=0. This gives this full perturbative solution:\n\nE_coeffs_sol = solve_cascade(kepler_eqs, E_coeffs, 0, M)\nE_pert = substitute(E_taylor, E_coeffs_sol)\n\nNumerically, the result again converges to that from Newton's method:\n\nfor n in 0:5\n    println(\"$n-th order solution: E = \", substitute(taylor(E_pert, M, 0:n), vals_earth))\nend\n\nBut unlike Newtons method, this example shows how perturbation theory also gives us the powerful symbolic series solution for E (before numbers for e and M are inserted). Our series matches this result from Wikipedia:\n\nE_wiki = 1/(1-e)*M - e/(1-e)^4*M^3/factorial(3) + (9e^2+e)/(1-e)^7*M^5/factorial(5)\n\nAlternatively, we can expand E in e instead of M, giving the solution (the trivial solution when e = 0 is E_0=M):\n\nE_taylor′ = series(E, e, 0:5)\nE_coeffs′ = taylor_coeff(E_taylor′, e)\nkepler_eqs′ = taylor_coeff(substitute(kepler, E => E_taylor′), e, 0:5)\nE_coeffs_sol′ = solve_cascade(kepler_eqs′, E_coeffs′, M, e)\nE_pert′ = substitute(E_taylor′, E_coeffs_sol′)\n\nThis looks very different from our first series E_pert. If they are the same, we should get 0 if we subtract and expand both as multivariate Taylor series in (eM). Indeed:\n\n@assert taylor(taylor(E_pert′ - E_pert, e, 0:4), M, 0:4) == 0 # use this as a test # hide\ntaylor(taylor(E_pert′ - E_pert, e, 0:4), M, 0:4)","category":"section"},{"location":"manual/types/#Supported-types-and-dispatch-in-Symbolics","page":"Supported types and dispatch in Symbolics","title":"Supported types and dispatch in Symbolics","text":"There is a tension between types as a representation of expression trees and types that are a subtype of types already present in Julia.\n\nWe want to be able to deal with expression trees in a unified way and not constrain expression trees themselves to be under an abstract type in Julia's type hierarchy. (For example, if we said that all expression trees are subtype of Real, then we couldn't represent array operations using the same expression tree.). But we also want to be able to pass in expression trees into places in existing code that accept Real values.\n\nWe accomplish this by wrapping expression trees in a simple wrapper type which is a subtype of our desired abstract type. For example, we wrap expression trees in the type Num which is a subtype of Real to make it behave like a Real number.\n\nThe methods on Num objects are forwarded to the wrapped expression tree. And care is taken so that an expression tree never internally contains Num – this is both for performance and separation of concerns.\n\nUser-facing APIs in Symbolics always take wrapped objects like Num, they are then internally unwrapped for expression tree manipulation.\n\nDue to it requiring such wrappers, we only fully support a limited number of types as both the types of expression trees and the type as Julia sees them.\n\nThese types are\n\nReal numbers (wrapped using Num)\ncomplex numbers (stored as Complex{Num} where Complex is from Base Julia)\narrays of Real and complex numbers (wrapped using Arr, so Arr{Num} or Arr{Complex{Num}})","category":"section"},{"location":"manual/types/#@variables-and-types","page":"Supported types and dispatch in Symbolics","title":"@variables and types","text":"Use the syntax @variables x::T to create a symbol named x of symbolic type T. If T is a subtype of any of the above listed types which support a wrapper, the resulting variable will be wrapped in that type. As seen in the examples below, x,z,X,Z all have a suitable wrapper type. Hence, their types are shown. However, s being of symbolic type String does not have a corresponding wrapper supported by Symbolics, and hence, it returns a Sym{String} object. This is the trivial expression tree of a single variable without a wrapper, and is not a subtype of String or AbstractString.\n\nusing Symbolics\n@variables x::Real z::Complex{Real} (X::Real)[1:10, 1:10] (Z::Complex{Real})[1:10] s::String\n\ntypeof(x)\n\ntypeof(z)\n\ntypeof(X)\n\ntypeof(Z)\n\ntypeof(s)","category":"section"},{"location":"manual/types/#Type-Wrapper-API","page":"Supported types and dispatch in Symbolics","title":"Type Wrapper API","text":"","category":"section"},{"location":"manual/types/#Symbolics.wrap","page":"Supported types and dispatch in Symbolics","title":"Symbolics.wrap","text":"wrap(x) -> Any\n\n\nWrap the symbolic or non-symbolic value x in the appropriate wrapper type.\n\n\n\n\n\n","category":"function"},{"location":"manual/types/#SymbolicUtils.unwrap","page":"Supported types and dispatch in Symbolics","title":"SymbolicUtils.unwrap","text":"unwrap(x) -> Int64\n\n\nReturn the inner Symbolic wrapped in a non-symbolic subtype. Defaults to returning the input as-is.\n\n\n\n\n\n","category":"function"},{"location":"manual/external/#Working-with-External-Symbolics-Packages:-SymPy,-Mathematica,-Oscar,-and-Beyond","page":"Working with External Symbolics Packages: SymPy, Mathematica, Oscar, and Beyond","title":"Working with External Symbolics Packages: SymPy, Mathematica, Oscar, and Beyond","text":"Symbolics.jl takes an inclusive development philosophy: yes there are other computer algebra systems such as SymPy and Mathematica, yes they can do some things that Symbolics.jl cannot natively do, and no that is not a bad thing. Instead, we maintain bridges to these other languages in order to encourage users to take full advantage of other tools as part of their workflow!\n\nThe following are the wrappers and interactions users should be aware of.","category":"section"},{"location":"manual/external/#Using-Symbolics.jl-with-SymPy","page":"Working with External Symbolics Packages: SymPy, Mathematica, Oscar, and Beyond","title":"Using Symbolics.jl with SymPy","text":"SymPy is a Python-based symbolic library. While it is generally not computationally performant, it is good in its completeness of features and as such it can be helpful to call its functions from time to time. Because of this, Symbolics.jl maintains extensions for SymPy.jl which facilitates translations. The extension is triggered by adding the SymPy.jl packages doing using SymPy. When this is done, Symbolics.jl gives functions which allow for translating to and from SymPy expressions:\n\nIn addition, many of the features pages include docstrings for functionality given by this bridge. These functions all have sympy in the name, and includes:\n\nsympy_simplify\nsympy_linear_solve\nsympy_algebraic_solve\nsympy_integrate\nsympy_limit\nsympy_simplify\nsympy_ode_solve","category":"section"},{"location":"manual/external/#Using-Symbolics.jl-with-Mathematica-/-Wolfram's-MathLink","page":"Working with External Symbolics Packages: SymPy, Mathematica, Oscar, and Beyond","title":"Using Symbolics.jl with Mathematica / Wolfram's MathLink","text":"The library SymbolicsMathLink.jl is capable of converting Symbolics.jl expressions for use with Mathematica calls via Wolfram's MathLink. The package requires an installation of either Mathematica or the free Wolfram Engine. It will attempt to find the installation at build time; if this fails, please see the installation troubleshoot on the MathLink.jl README.\n\nRound-trip conversion is given by the functions:\n\nexpr_to_mathematica(juliaSymbolicExpression)\nmathematica_to_expr(W`Some Mathematica expression`)\n\nSome examples in action include using Mathematica for equation solving:\n\njulia> using SymbolicsMathLink\n\njulia> @variables x;\njulia> expr = x^2 + x - 1;\n\njulia> result = wcall(\"Solve\", expr~0)\n2-element Array{Num,1}:\n    -1 + x\n    1 + x\n\nand solving differential equations:\n\njulia> @variables vars(x)[1:2];\njulia> expr = Differential(x)(vars[1]) + 2\n2 + Differential(x)((vars(x))[1])\njulia> result = wcall(\"DSolveValue\", expr~0, vars[1], x)\nC_1 - 2x","category":"section"},{"location":"manual/external/#Groebner-Basis-via-Groebner.jl","page":"Working with External Symbolics Packages: SymPy, Mathematica, Oscar, and Beyond","title":"Groebner Basis via Groebner.jl","text":"Groebner.jl is a very efficient system for computing Groebner basis written in Julia. Its publication  details how it is much more efficient than Maple, msolve, Mathematica, and Singular for these computing a Groebner basis. As such, it is highly recommended that one use this system for the computation. Symbolics.jl provides an extension which automatically converts Symbolics.jl polynomials into its specialized form for the computation and converts the result back, and thus no work is required on the users end for integrating.","category":"section"},{"location":"manual/external/#Nemo.jl","page":"Working with External Symbolics Packages: SymPy, Mathematica, Oscar, and Beyond","title":"Nemo.jl","text":"Nemo.jl's abstract algebra functionality (and by extension FLINT)  is used as part of many of the symbolic solver routines. If Nemo is required an error message specifying the requirement to load Nemo.jl will be given. For more information, see the  symbolic solver page","category":"section"},{"location":"manual/external/#Symbolics.symbolics_to_sympy","page":"Working with External Symbolics Packages: SymPy, Mathematica, Oscar, and Beyond","title":"Symbolics.symbolics_to_sympy","text":"symbolics_to_sympy(expr)\n\nConverts a Symbolics.jl expression to a SymPy expression. It is represented in SymPy.jl format and thus can use all of the wrapped functionality from SymPy.jl.\n\nFor conversion back to Symbolics, see sympy_to_symbolics.\n\nArguments\n\nexpr: A Symbolics.jl expression\n\nExample\n\nusing Symbolics\n@variables x y\nexpr = x^2 + y\nsympy_expr = symbolics_to_sympy(expr)\n\n\n\n\n\n","category":"function"},{"location":"manual/external/#Symbolics.sympy_to_symbolics","page":"Working with External Symbolics Packages: SymPy, Mathematica, Oscar, and Beyond","title":"Symbolics.sympy_to_symbolics","text":"sympy_to_symbolics(sympy_expr, vars)\n\nConverts a SymPy expression to Symbolics.jl.\n\nArguments\n\nsympy_expr: SymPy expression.\nvars: List or dictionary of Symbolics variables.\n\nExample\n\n@variables x y\nsympy_expr = SymPy.Sym(\"x\")^2 + SymPy.Sym(\"y\")\nsymbolics_expr = sympy_to_symbolics(sympy_expr, [x, y])\n\n\n\n\n\n","category":"function"},{"location":"manual/external/#Symbolics.groebner_basis","page":"Working with External Symbolics Packages: SymPy, Mathematica, Oscar, and Beyond","title":"Symbolics.groebner_basis","text":"groebner_basis(polynomials; kwargs...)\n\nComputes a Groebner basis of the ideal generated by the given polynomials using Groebner.jl as the backend.\n\nnote: Note\nThis function requires a Groebner bases backend (such as Groebner.jl) to be loaded.\n\nThe basis is guaranteed to be unique. The algorithm is randomized, and the output is correct with high probability.\n\nIf a coefficient in the resulting basis becomes too large to be represented exactly, DomainError is thrown.\n\nOptional Arguments\n\nThe Groebner.jl backend provides a number of useful keyword arguments, which are also available for this function. See ?Groebner.groebner.\n\nExample\n\njulia> using Symbolics, Groebner\n\njulia> @variables x y;\n\njulia> groebner_basis([x*y^2 + x, x^2*y + y])\n\n\n\n\n\n","category":"function"},{"location":"manual/metadata/#Metadata","page":"Metadata","title":"Metadata","text":"Symbolics.jl provides a metadata system for attaching additional information to symbolic variables. This system allows for extensible annotations that can be used to store default values, source information, and custom user-defined metadata.","category":"section"},{"location":"manual/metadata/#Using-Metadata","page":"Metadata","title":"Using Metadata","text":"Metadata can be attached to variables when they are created with the @variables macro. Common metadata includes default values and other annotations:\n\nusing Symbolics\n\n# Variable with default value\n@variables x=1.0 y=2.0\n\n# Variables with custom metadata (once registered)\n@variables z [description=\"Temperature in Kelvin\"]","category":"section"},{"location":"manual/metadata/#Extending-Metadata","page":"Metadata","title":"Extending Metadata","text":"You can define custom metadata types for use with the @variables macro by defining a new metadata type and registering it:\n\nusing Symbolics\n\n# Define a custom metadata type\nstruct MyCustomMetadata <: Symbolics.AbstractVariableMetadata end\n\n# Register it for use in @variables\nSymbolics.option_to_metadata_type(::Val{:my_custom}) = MyCustomMetadata\n\n# Now you can use it\n@variables x [my_custom = \"some value\"]","category":"section"},{"location":"manual/metadata/#Metadata-API","page":"Metadata","title":"Metadata API","text":"","category":"section"},{"location":"manual/metadata/#Symbolics.VariableDefaultValue","page":"Metadata","title":"Symbolics.VariableDefaultValue","text":"struct VariableDefaultValue <: Symbolics.AbstractVariableMetadata\n\nSymbolic metadata key for storing the default value of a symbolic variable.\n\n\n\n\n\n","category":"type"},{"location":"manual/metadata/#Symbolics.VariableSource","page":"Metadata","title":"Symbolics.VariableSource","text":"struct VariableSource <: Symbolics.AbstractVariableMetadata\n\nSymbolic metadata key for storing the macro used to create a symbolic variable.\n\n\n\n\n\n","category":"type"},{"location":"manual/metadata/#Symbolics.option_to_metadata_type","page":"Metadata","title":"Symbolics.option_to_metadata_type","text":"option_to_metadata_type(\n    _::Val{opt}\n) -> Type{SymbolicsLatexifyExt.SymLatexWrapper}\n\n\nDefine a new metadata key assignable in @variables. This function should take Val{name} where name is a Symbol, and return the key type for the given metadata name name. For example,\n\nSymbolics.option_to_metadata_type(::Val{:custom_name}) = CustomType\n\nAllows the following syntax:\n\n@variables x [custom_name = 1]\n\nAnd stores 1 as the value associated with the CustomType key in the symbolic metadata of x.\n\n\n\n\n\n","category":"function"},{"location":"manual/parsing/#Parsing-Julia-Expressions-to-Symbolic-Expressions","page":"Parsing Julia Expressions to Symbolic Expressions","title":"Parsing Julia Expressions to Symbolic Expressions","text":"Julia expressions such as :(y - x) are fundamentally different from symbolic expressions, as they do not have an algebra defined on them. Thus, it can be very helpful when building domain-specific languages (DSLs) and parsing files to convert from Julia expressions to Symbolics.jl expressions for further manipulation. Towards this end is the parse_expr_to_symbolic which performs the parsing.\n\nwarning: Warning\nTake the limitations mentioned in the parse_expr_to_symbolic docstrings seriously! Because Julia expressions contain no symbolic metadata, there is limited information and thus the parsing requires heuristics to work.","category":"section"},{"location":"manual/parsing/#Symbolics.parse_expr_to_symbolic","page":"Parsing Julia Expressions to Symbolic Expressions","title":"Symbolics.parse_expr_to_symbolic","text":"parse_expr_to_symbolic(ex, mod::Union{Module,AbstractDict})\n\nApplies the parse_expr_to_symbolic function in the current module, i.e. parse_expr_to_symbolic(ex, mod) where mod is the module of the function caller.\n\nArguments\n\nex: the expression to parse\nmod: the module or dictionary to apply the parsing in. See the limitations section for details.\n\nExample\n\nex = :(y(t) ~ x(t))\nparse_expr_to_symbolic(ex,Main) # gives the symbolic expression `y(t) ~ x(t)` in empty Main\n\n# Now do a whole system\n\nex = [:(y ~ x)\n      :(y ~ -2x + 3 / z)\n      :(z ~ 2)]\neqs = parse_expr_to_symbolic.(ex, (Main,))\n\n@variables x y z\nex = [y ~ x\n      y ~ -2x + 3 / z\n      z ~ 2]\nall(isequal.(eqs,ex)) # true\n\nLimitations\n\nSymbolic-ness Tied to Environment Definitions\n\nThe parsing to a symbolic expression has to be able to recognize the difference between functions, numbers, and globals defined within one's Julia environment and those that are to be made symbolic. The way this functionality handles this problem is that it does not define anything as symbolic that is already defined in the chosen mod module. For example, f(x,y) will have f as non-symbolic if the function f (named f) is defined in mod, i.e. if isdefined(mod,:f) is true. When the symbol is defined, it will be replaced by its value. Notably, this means that the parsing behavior changes depending on the environment that it is applied.\n\nFor example:\n\nparse_expr_to_symbolic(:(x - y),@__MODULE__) # x - y\nx = 2.0\nparse_expr_to_symbolic(:(x - y),@__MODULE__) # 2.0 - y\n\nThis is required to detect that standard functions like - are functions instead of symbolic symbols. For safety, one should create anonymous modules or other sub-environments to ensure no stray variables are defined.\n\nMetadata is Blank\n\nBecause all the variables defined by the expressions are not defined with the standard @variables, there is no metadata that is or can be associated with any of the generated variables. Instead, they all have blank metadata, but are defined in the Real domain. Thus, the variables which come out of this parsing may not evaluate as equal to a symbolic variable defined elsewhere.\n\n\n\n\n\n","category":"function"},{"location":"manual/variables/#Variable-and-Equation-Types","page":"Variable and Equation Types","title":"Variable and Equation Types","text":"Symbolics IR mirrors the Julia AST but allows for easy mathematical manipulation by itself following mathematical semantics. The base of the IR is the Sym type, which defines a symbolic variable. Registered (mathematical) functions on Syms (or iscall objects) return an expression that iscall. For example, op1 = x+y is one symbolic object and op2 = 2z is another, and so op1*op2 is another tree object. Then, at the top, an Equation, normally written as op1 ~ op2, defines the symbolic equality between two operations.","category":"section"},{"location":"manual/variables/#Types","page":"Variable and Equation Types","title":"Types","text":"Sym, Term, and FnType are from SymbolicUtils.jl. Note that in Symbolics, we always use Sym{Real}, Term{Real}, and FnType{Tuple{Any}, Real}. To get the arguments of an iscall object, use arguments(t::Term), and to get the operation, use operation(t::Term). However, note that one should never dispatch on Term or test isa Term. Instead, one needs to use SymbolicUtils.iscall to check if arguments and operation is defined.","category":"section"},{"location":"manual/variables/#A-note-about-functions-restricted-to-Numbers","page":"Variable and Equation Types","title":"A note about functions restricted to Numbers","text":"Sym and Term objects are NOT subtypes of Number. Symbolics provides a simple wrapper type called Num which is a subtype of Real. Num wraps either a Sym or a Term or any other object, defines the same set of operations as symbolic expressions and forwards those to the values it wraps. You can use Symbolics.value function to unwrap a Num.\n\nBy default, the @variables macros return Num-wrapped objects to allow calling functions which are restricted to Number or Real.\n\nusing Symbolics\n@variables t x y z(t);\nSymbolics.operation(Symbolics.value(x + y))\n\nSymbolics.operation(Symbolics.value(z))\n\nSymbolics.arguments(Symbolics.value(x + y))\n\nNote that Julia converts irrationals — like π and ℯ — to Float64 whenever they are involved in arithmetic with other numbers, including integers.  An expression like 2π will be converted to a float immediately, so an expression like 2π * x will leave the symbolic x multiplied by a Float64.  It may be preferable to have a symbolic representation of π also, which can be achieved with Num(π).  For generic programming, it may be helpful to simply redefine the variable π to be of the same type as some other argument, as in\n\nfunction f(x)\n    let π=oftype(x, π)\n        1 + (2//3 + 4π/5) * x\n    end\nend\nf(t)\n\nThis will work for any floating-point input, as well as symbolic input.","category":"section"},{"location":"manual/variables/#Symbolic-Control-Flow","page":"Variable and Equation Types","title":"Symbolic Control Flow","text":"Control flow can be expressed in Symbolics.jl in the following way:","category":"section"},{"location":"manual/variables/#Inspection-Functions","page":"Variable and Equation Types","title":"Inspection Functions","text":"","category":"section"},{"location":"manual/variables/#Variable-Utilities","page":"Variable and Equation Types","title":"Variable Utilities","text":"","category":"section"},{"location":"manual/variables/#Variable-Parsing","page":"Variable and Equation Types","title":"Variable Parsing","text":"For implementing custom variable-creating macros:","category":"section"},{"location":"manual/variables/#Symbolics.@variables","page":"Variable and Equation Types","title":"Symbolics.@variables","text":"Define one or more unknown variables.\n\n@variables t α σ(..) β[1:2]\n@variables w(..) x(t) y z(t, α, x)\n\nexpr = β[1]* x + y^α + σ(3) * (z - t) - β[2] * w(t - 1)\n\n(..) signifies that the value should be left uncalled.\n\nSymbolics supports creating variables that denote an array of some size.\n\njulia> @variables x[1:3]\n1-element Vector{Symbolics.Arr{Num, 1}}:\n x[1:3]\n\njulia> @variables y[1:3, 1:6] # support for  tensors\n1-element Vector{Symbolics.Arr{Num, 2}}:\n y[1:3,1:6]\n\njulia> @variables t z(t)[1:3] # also works for dependent variables\n2-element Vector{Any}:\n t\n  (z(t))[1:3]\n\nA symbol or expression that represents an array can be turned into an array of symbols or expressions using the scalarize function.\n\njulia> Symbolics.scalarize(z)\n3-element Vector{Num}:\n (z(t))[1]\n (z(t))[2]\n (z(t))[3]\n\nNote that @variables returns a vector of all the defined variables.\n\n@variables can also take runtime symbol values by the $ interpolation operator, and in this case, @variables doesn't automatically assign the value, instead, it only returns a vector of symbolic variables. All the rest of the syntax also applies here.\n\njulia> a, b, c = :runtime_symbol_value, :value_b, :value_c\n(:runtime_symbol_value, :value_b, :value_c)\n\njulia> vars = @variables t $a $b(t) $c(t)[1:3]\n4-element Vector{Any}:\n      t\n runtime_symbol_value\n   value_b(t)\n       (value_c(t))[1:3]\n\njulia> (t, a, b, c)\n(t, :runtime_symbol_value, :value_b, :value_c)\n\n\n\n\n\n","category":"macro"},{"location":"manual/variables/#Symbolics.variable","page":"Variable and Equation Types","title":"Symbolics.variable","text":"variable(name::Symbol, idx::Integer...; T=Real)\n\nCreate a variable with the given name along with subscripted indices with the symtype=T. When T=FnType, it creates a symbolic function.\n\njulia> Symbolics.variable(:x, 4, 2, 0)\nx₄ˏ₂ˏ₀\n\njulia> Symbolics.variable(:x, 4, 2, 0, T=Symbolics.FnType)\nx₄ˏ₂ˏ₀⋆\n\nAlso see variables.\n\n\n\n\n\n","category":"function"},{"location":"manual/variables/#Symbolics.variables","page":"Variable and Equation Types","title":"Symbolics.variables","text":"variables(name::Symbol, indices...)\n\nCreate a multi-dimensional array of individual variables named with subscript notation. Use @variables instead to create symbolic array variables (as opposed to array of variables). See variable to create one variable with subscripts.\n\njulia> Symbolics.variables(:x, 1:3, 3:6)\n3×4 Matrix{Num}:\n x₁ˏ₃  x₁ˏ₄  x₁ˏ₅  x₁ˏ₆\n x₂ˏ₃  x₂ˏ₄  x₂ˏ₅  x₂ˏ₆\n x₃ˏ₃  x₃ˏ₄  x₃ˏ₅  x₃ˏ₆\n\n\n\n\n\n","category":"function"},{"location":"manual/variables/#Symbolics.Equation","page":"Variable and Equation Types","title":"Symbolics.Equation","text":"struct Equation\n\nAn equality relationship between two expressions.\n\nFields\n\nlhs: The expression on the left-hand side of the equation.\nrhs: The expression on the right-hand side of the equation.\n\n\n\n\n\n","category":"type"},{"location":"manual/variables/#Base.:~-Tuple{Num, Num}","page":"Variable and Equation Types","title":"Base.:~","text":"~(lhs, rhs) -> Any\n\n\nCreate an Equation out of two Num instances, or an Num and a Number.\n\nExamples\n\njulia> using Symbolics\n\njulia> @variables x y;\n\njulia> @variables A[1:3, 1:3] B[1:3, 1:3];\n\njulia> x ~ y\nx ~ y\n\njulia> x - y ~ 0\nx - y ~ 0\n\njulia> A ~ B\n(broadcast(~, A, B))[1:3,1:3]\n\njulia> A .~ 3x\n(broadcast(~, A, 3x))[1:3,1:3]\n\n\n\n\n\n","category":"method"},{"location":"manual/variables/#Base.ifelse-Tuple{Num, Any, Any}","page":"Variable and Equation Types","title":"Base.ifelse","text":"ifelse(cond::Num, x, y)\n\nSymbolic conditional expression. Returns x if cond evaluates to true, and y if cond  evaluates to false. This allows encoding conditional logic in symbolic expressions.\n\nExamples\n\n@variables a b c\nifelse(a > b, c, 0)  # Returns c if a > b, otherwise 0\n\n\n\n\n\n","category":"method"},{"location":"manual/variables/#TermInterface.iscall","page":"Variable and Equation Types","title":"TermInterface.iscall","text":"iscall(\n    s::SymbolicUtils.BasicSymbolicImpl.var\"typeof(BasicSymbolicImpl)\"{T} where T\n) -> Bool\n\n\nCheck if a symbolic expression expr represents a function call. Returns true if the  expression is a composite expression with an operation and arguments, false otherwise.\n\nThis function is fundamental for traversing and analyzing symbolic expressions. In  SymbolicUtils.jl, an expression is considered a \"call\" if it represents a function  application (including operators like +, -, *, etc.).\n\nExamples\n\nusing SymbolicUtils\n@variables x y\n\n# Basic variables are not calls\niscall(x)           # false\n\n# Function calls are calls  \nexpr = sin(x + y)\niscall(expr)        # true\n\n# Arithmetic expressions are calls\niscall(x + y)       # true\niscall(x * y)       # true\n\nSee also: operation, arguments\n\n\n\n\n\n","category":"function"},{"location":"manual/variables/#TermInterface.operation","page":"Variable and Equation Types","title":"TermInterface.operation","text":"operation(\n    x::SymbolicUtils.BasicSymbolicImpl.var\"typeof(BasicSymbolicImpl)\"{T}\n) -> Any\n\n\nExtract the operation (function) from a symbolic function call expression. Only valid for expressions where iscall(expr) returns true.\n\nReturns the function/operator that is being applied in the expression. For basic arithmetic, this returns the operator function (+, -, *, /, ^). For function calls like sin(x), this returns the function sin.\n\nExamples\n\nusing SymbolicUtils\n@variables x y\n\n# Arithmetic operations\nexpr1 = x + y\noperation(expr1)    # returns +\n\nexpr2 = x * y  \noperation(expr2)    # returns *\n\n# Function calls\nexpr3 = sin(x)\noperation(expr3)    # returns sin\n\n# Nested expressions\nexpr4 = sin(x + y)\noperation(expr4)    # returns sin\noperation(arguments(expr4)[1])  # returns +\n\nSee also: TermInterface.iscall, arguments\n\n\n\n\n\n","category":"function"},{"location":"manual/variables/#TermInterface.arguments","page":"Variable and Equation Types","title":"TermInterface.arguments","text":"arguments(x, op::Function)\n\nGet the arguments of the symbolic expression x with respect to the operation or function op.\n\n\n\n\n\narguments(expr)\n\nExtract the arguments from a symbolic function call expression. Only valid for expressions where iscall(expr) returns true.\n\nReturns a collection (typically a vector) containing the arguments passed to the operation. For binary operations like + or *, this returns a collection of all operands. For function calls, this returns the function arguments.\n\nExamples\n\nusing SymbolicUtils\n@variables x y z\n\n# Binary arithmetic operations\nexpr1 = x + y\narguments(expr1)    # returns collection containing x and y\n\nexpr2 = x * y * z  \narguments(expr2)    # returns collection containing x, y, and z\n\n# Function calls\nexpr3 = sin(x)\narguments(expr3)    # returns collection containing x\n\n# Nested expressions\nexpr4 = sin(x + y)\narguments(expr4)             # returns collection containing (x + y)\narguments(arguments(expr4)[1])  # returns collection containing x and y\n\nSee also: iscall, operation\n\n\n\n\n\n","category":"function"},{"location":"manual/variables/#Symbolics._parse_vars","page":"Variable and Equation Types","title":"Symbolics._parse_vars","text":"_parse_vars(macroname, type, x) -> Expr\n_parse_vars(macroname, type, x, transform) -> Expr\n\n\nThe worker function for parse_vars. This returns the expanded code, exactly as it should be run. In other words, this does not require sanitization and the result should be passed through esc before returning from the macro. parse_vars does this automatically. This function also guarantees that the last expression in the returned Expr(:block) is an Expr(:vect) of the identifiers for the created variables.\n\n\n\n\n\n","category":"function"},{"location":"manual/sparsity_detection/#Structure-and-Sparsity-Detection","page":"Structure and Sparsity Detection","title":"Structure and Sparsity Detection","text":"Using the tracing system provided by Symbolics.jl expressions, Symbolics.jl can automatically detect the sparsity patterns of Julia functions efficiently. This functionality is described in more detail in the paper:\n\n@article{gowda2019sparsity,\n  title={Sparsity Programming: Automated Sparsity-Aware Optimizations in Differentiable Programming},\n  author={Gowda, Shashi and Ma, Yingbo and Churavy, Valentin and Edelman, Alan and Rackauckas, Christopher},\n  year={2019}\n}\n\nPlease cite this work if the functionality is used.","category":"section"},{"location":"manual/sparsity_detection/#Sparsity-Detection","page":"Structure and Sparsity Detection","title":"Sparsity Detection","text":"","category":"section"},{"location":"manual/sparsity_detection/#Structure-Detection","page":"Structure and Sparsity Detection","title":"Structure Detection","text":"","category":"section"},{"location":"manual/sparsity_detection/#ADTypes.jl-interface","page":"Structure and Sparsity Detection","title":"ADTypes.jl interface","text":"","category":"section"},{"location":"manual/sparsity_detection/#Symbolics.jacobian_sparsity","page":"Structure and Sparsity Detection","title":"Symbolics.jacobian_sparsity","text":"jacobian_sparsity(\n    exprs::AbstractArray,\n    vars::AbstractArray\n) -> SparseArrays.SparseMatrixCSC{Bool, Int64}\n\n\nReturn the sparsity pattern of the Jacobian of an array of expressions with respect to an array of variable expressions.\n\nArguments\n\nexprs: an array of symbolic expressions.\nvars: an array of symbolic variables.\n\nExamples\n\njulia> using Symbolics\n\njulia> vars = @variables x₁ x₂;\n\njulia> exprs = [2x₁, 3x₂, 4x₁ * x₂];\n\njulia> Symbolics.jacobian_sparsity(exprs, vars)\n3×2 SparseArrays.SparseMatrixCSC{Bool, Int64} with 4 stored entries:\n 1  ⋅\n ⋅  1\n 1  1\n\n\n\n\n\njacobian_sparsity(\n    f!,\n    output::AbstractArray,\n    input::AbstractArray,\n    args...;\n    kwargs...\n) -> SparseArrays.SparseMatrixCSC{Bool, Int64}\n\n\nReturn the sparsity pattern of the Jacobian of the mutating function f!.\n\nArguments\n\nf!: an in-place function f!(output, input, args...; kwargs...).\noutput: output array.\ninput: input array.\n\nThe eltype of output and input can be either symbolic or primitive.\n\nExamples\n\njulia> using Symbolics\n\njulia> f!(y, x) = y .= [x[2], 2x[1], 3x[1] * x[2]];\n\njulia> output = Vector{Float64}(undef, 3);\n\njulia> input = Vector{Float64}(undef, 2);\n\njulia> Symbolics.jacobian_sparsity(f!, output, input)\n3×2 SparseArrays.SparseMatrixCSC{Bool, Int64} with 4 stored entries:\n ⋅  1\n 1  ⋅\n 1  1\n\n\n\n\n\n","category":"function"},{"location":"manual/sparsity_detection/#Symbolics.hessian_sparsity","page":"Structure and Sparsity Detection","title":"Symbolics.hessian_sparsity","text":"hessian_sparsity(\n    expr,\n    vars::AbstractVector;\n    full,\n    linearity_propagator\n) -> Union{SparseArrays.SparseMatrixCSC{Bool, Int64}, SparseArrays.SparseMatrixCSC{Int64, Int64}}\n\n\nReturn the sparsity pattern of the Hessian of an expression with respect to an array of variable expressions.\n\nArguments\n\nexpr: a symbolic expression.\nvars: a vector of symbolic variables.\n\nExamples\n\njulia> using Symbolics\n\njulia> vars = @variables x₁ x₂;\n\njulia> expr = 3x₁^2 + 4x₁ * x₂;\n\njulia> Symbolics.hessian_sparsity(expr, vars)\n2×2 SparseArrays.SparseMatrixCSC{Bool, Int64} with 3 stored entries:\n 1  1\n 1  ⋅\n\n\n\n\n\nhessian_sparsity(\n    f::Function,\n    input::AbstractVector,\n    args...;\n    full,\n    kwargs...\n) -> Union{SparseArrays.SparseMatrixCSC{Bool, Int64}, SparseArrays.SparseMatrixCSC{Int64, Int64}}\n\n\nReturn the sparsity pattern of the Hessian of the given function f.\n\nArguments\n\nf: an out-of-place function f(input, args...; kwargs...).\ninput: a vector of input values whose eltype can be either symbolic or primitive.\n\nExamples\n\njulia> using Symbolics\n\njulia> f(x) = 4x[1] * x[2] - 5x[2]^2;\n\njulia> input = Vector{Float64}(undef, 2);\n\njulia> Symbolics.hessian_sparsity(f, input)\n2×2 SparseArrays.SparseMatrixCSC{Bool, Int64} with 3 stored entries:\n ⋅  1\n 1  1\n\n\n\n\n\n","category":"function"},{"location":"manual/sparsity_detection/#Symbolics.islinear","page":"Structure and Sparsity Detection","title":"Symbolics.islinear","text":"islinear(ex, u)\n\n\nCheck if an expression is linear with respect to a list of variable expressions.\n\n\n\n\n\n","category":"function"},{"location":"manual/sparsity_detection/#Symbolics.isaffine","page":"Structure and Sparsity Detection","title":"Symbolics.isaffine","text":"isaffine(ex, u)\n\n\nCheck if an expression is affine with respect to a list of variable expressions.\n\n\n\n\n\n","category":"function"},{"location":"manual/sparsity_detection/#Symbolics.SymbolicsSparsityDetector","page":"Structure and Sparsity Detection","title":"Symbolics.SymbolicsSparsityDetector","text":"SymbolicsSparsityDetector <: ADTypes.AbstractSparsityDetector\n\nSparsity detection algorithm based on the Symbolics.jl tracing system.\n\nThis type makes Symbolics.jl compatible with the ADTypes.jl sparsity detection framework. The following functions are implemented:\n\nADTypes.jacobian_sparsity based on Symbolics.jacobian_sparsity\nADTypes.hessian_sparsity based on Symbolics.hessian_sparsity\n\nReference\n\nSparsity Programming: Automated Sparsity-Aware Optimizations in Differentiable Programming, Gowda et al. (2019)\n\n\n\n\n\n","category":"type"},{"location":"manual/integration/#Symbolic-Integrals","page":"Symbolic Integrals","title":"Symbolic Integrals","text":"Symbolics.jl provides a the Integral operator for defining integrals. These can be used with various functionalities in order to represent integro-differential equations and as a representation for symbolic solving of integrals.","category":"section"},{"location":"manual/integration/#Defining-Symbolic-Integrals","page":"Symbolic Integrals","title":"Defining Symbolic Integrals","text":"Note that integration domains are defined using  DomainSets.jl.","category":"section"},{"location":"manual/integration/#Solving-Symbolic-Integrals","page":"Symbolic Integrals","title":"Solving Symbolic Integrals","text":"Symbolics.jl currently has the following options for solving integrals symbolically:\n\nPackage Method Description Pros Cons\nSymbolicIntegration.jl Risch Algorithm Implements theoretical Risch algorithm for elementary functions Mathematically rigorous, returns exact symbolic results, handles rational functions and transcendental functions (exp, log, trig) Still in early development, unstable, limited to specific function classes, no support for algebraic functions\nSymbolicIntegration.jl Rule-Based Method Applies over 3,400 integration rules systematically Handles non-integer powers, supports multiple symbolic variables, more flexible than pure Risch Rule-dependent success, no theoretical completeness guarantee, limited by predefined rule set\nSymbolicNumericIntegration.jl Symbolic-Numeric Hybrid Uses numeric integrators with symbolic regression machine learning methods Can solve some hard integrals very fast and easily, works differently from pure symbolic methods Can be unreliable in easy cases, will give floats (0.5) instead of rational values (1//2), precision loss\nSymPy's Integrate Hybrid Methods Uses SymPy (through SymPy.jl) to integrate the expression Reasonably robust and tested solution, mature implementation Extremely slow, Python overhead","category":"section"},{"location":"manual/integration/#SymbolicIntegration.jl","page":"Symbolic Integrals","title":"SymbolicIntegration.jl","text":"SymbolicIntegration.jl provides pure symbolic integration using multiple algorithmic approaches. Unlike numerical methods, it returns exact symbolic results with rational coefficients (e.g., 1//2 instead of 0.5). The package implements a flexible framework for symbolic integration that uses Julia's multiple dispatch to select appropriate algorithms for different types of integrands.\n\nThe package offers two main integration methods:","category":"section"},{"location":"manual/integration/#Risch-Algorithm-Method","page":"Symbolic Integrals","title":"Risch Algorithm Method","text":"The RischMethod implements the theoretical Risch algorithm for integrating:\n\nPolynomial functions\nRational functions  \nExponential functions\nLogarithmic functions\nTrigonometric functions\nCombinations of the above\n\nThis method is mathematically rigorous and provides guaranteed results when an elementary antiderivative exists. However, it is still under development and may not handle all cases robustly.","category":"section"},{"location":"manual/integration/#Rule-Based-Method","page":"Symbolic Integrals","title":"Rule-Based Method","text":"The rule-based approach systematically applies over 3,400 integration rules to solve integrals:\n\nHandles non-integer powers and algebraic functions\nSupports more complex integrations than pure Risch\nCan handle multiple symbolic variables\nMore flexible but depends on the predefined rule set\n\nThe package automatically tries the Risch algorithm first, then falls back to rule-based methods if needed.\n\nFor using SymbolicIntegration.jl, see the SymbolicIntegration.jl repository  for more details. Quick examples:\n\nusing Symbolics\nusing SymbolicIntegration\n\n@variables x\n\n# Basic integrations (automatic method selection)\nintegrate(x^2, x)           # Returns (1//3)*(x^3)\nintegrate(1/x, x)           # Returns log(x)\nintegrate(exp(x), x)        # Returns exp(x)\nintegrate(1/(x^2 + 1), x)   # Returns atan(x)\n\n# Rational function with complex roots (typically uses Risch)\nf = (x^3 + x^2 + x + 2)/(x^4 + 3*x^2 + 2)\nintegrate(f, x)  # Returns (1//2)*log(2 + x^2) + atan(x)\n\n# Nested transcendental functions (uses Risch)\nintegrate(1/(x*log(x)), x)  # Returns log(log(x))\n\n# Explicit Risch method selection\nintegrate(sin(x)*cos(x), x, RischMethod())\n\n# Configurable Risch method\nrisch = RischMethod(use_algebraic_closure=true, catch_errors=false)\nintegrate(exp(x)/(1 + exp(x)), x, risch)\n\n# Rule-based method for cases not handled by Risch\nintegrate(x^(1/2), x)       # Uses rule-based method for non-integer powers\nintegrate(sqrt(x + 1), x)   # Handles algebraic functions via rules","category":"section"},{"location":"manual/integration/#SymbolicNumericIntegration.jl","page":"Symbolic Integrals","title":"SymbolicNumericIntegration.jl","text":"SymbolicNumericIntegration.jl is a package for solving symbolic integrals using numerical methods.  Specifically, it mixes numerical integration with machine learning symbolic regression in order to discover the basis for the integrals solution, for which it then finds the coefficients and uses differentiation to prove the correctness of the result. While this technique is unusual and new, see the paper for details, it has the advantage of working very differently from the purely symbolic methods, and thus the problems which it finds hard can be entirely different from ones which the purely symbolic methods find hard. That is, while purely symbolic methods have difficulty depending on the complexity of the expression, this method has difficulty depending on the uniqueness of the numerical solution of the expression, and there are many complex expressions which have a very distinct solution behavior and thus can be easy to solve through this method.\n\nOne major downside to this method is that, because it works numerically, there can be precision loss in the coefficients. Thus the returned solution may have 0.5 instead of 1//2. \n\nFor using SymbolicNumericIntegration.jl, see the SymbolicNumericIntegration.jl documentation for more details. A quick example is:\n\nusing Symbolics\nusing SymbolicNumericIntegration\n\n@variables x a b\n\nintegrate(3x^3 + 2x - 5)\n# (x^2 + (3 // 4) * (x^4) - (5 // 1) * x, 0, 0)\n\nintegrate(exp(a * x), x; symbolic = true)\n# (exp(a * x) / a, 0, 0)\n\nintegrate(sin(a * x) * cos(b * x), x; symbolic = true, detailed = false)\n# (-a * cos(a * x) * cos(b * x) - b * sin(a * x) * sin(b * x)) / (a^2 - (b^2))","category":"section"},{"location":"manual/integration/#SymPy","page":"Symbolic Integrals","title":"SymPy","text":"The function sympy_integrate allows one to call  SymPy's integration functionality. While it's generally slow, if you leave your computer on for long enough it can solve some difficult expressions.","category":"section"},{"location":"manual/integration/#Symbolics.Integral","page":"Symbolic Integrals","title":"Symbolics.Integral","text":"Integral(domain)\n\nDefines an Integral operator I(ex) which represents the integral of I of the expression ex over the domain. Note that the domain must be a  Symbolics.VarDomainPairing where the chosen variable is the variable being integrated over, i.e. Integral(x in domain) means that I is the integral operator with respect to dx.\n\nExamples\n\nI1 = Integral(x in ClosedInterval(1, 5))\nI2 = Integral(x in ClosedInterval(1, 5))\n\n@variables a b\nI = Integral(x in ClosedInterval(a, b))\n@test isequal(I(0), 0)\n@test isequal(I(2), 2*(b -a))\n\n\n\n\n\n","category":"type"},{"location":"manual/integration/#Symbolics.sympy_integrate","page":"Symbolic Integrals","title":"Symbolics.sympy_integrate","text":"sympy_integrate(expr, var)\n\nComputes indefinite integral of expr w.r.t. var using SymPy.\n\nArguments\n\nexpr: Symbolics expression.\nvar: Symbolics variable.\n\nReturns\n\nSymbolics integral.\n\nExample\n\n@variables x\nexpr = x^2\nresult = sympy_integrate(expr, x)\n\n\n\n\n\n","category":"function"},{"location":"tutorials/auto_parallel/#Automated-Sparse-Parallelism-of-Julia-Functions-via-Tracing","page":"Automated Sparse Parallelism of Julia Functions via Tracing","title":"Automated Sparse Parallelism of Julia Functions via Tracing","text":"Because the Symbolics.jl expressions obey Julia semantics, one can directly transform existing Julia functions into Symbolics.jl symbolic representations of the function by simply inputting the symbolic values into the function and using what is returned. For example, let's take the following numerical PDE discretization:\n\nusing Symbolics, LinearAlgebra, SparseArrays, Plots\n\n# Define the constants for the PDE\nconst α₂ = 1.0\nconst α₃ = 1.0\nconst β₁ = 1.0\nconst β₂ = 1.0\nconst β₃ = 1.0\nconst r₁ = 1.0\nconst r₂ = 1.0\nconst _DD = 100.0\nconst γ₁ = 0.1\nconst γ₂ = 0.1\nconst γ₃ = 0.1\nconst N = 32\nconst X = reshape([i for i in 1:N for j in 1:N], N, N)\nconst Y = reshape([j for i in 1:N for j in 1:N], N, N)\nconst α₁ = 1.0 .* (X .>= 4*N/5)\n\nconst Mx = Array(Tridiagonal([1.0 for i in 1:N-1], [-2.0 for i in 1:N], [1.0 for i in 1:N-1]))\nconst My = copy(Mx)\nMx[2, 1] = 2.0\nMx[end-1,end] = 2.0\nMy[1, 2] = 2.0\nMy[end,end-1] = 2.0\n\n# Define the discretized PDE as an ODE function\nfunction f(u, p, t)\n    A = u[:,:,1]\n    B = u[:,:,2]\n    C = u[:,:,3]\n    MyA = My*A\n    AMx = A*Mx\n    DA = @. _DD*(MyA + AMx)\n    dA = @. DA + α₁ - β₁*A - r₁*A*B + r₂*C\n    dB = @. α₂ - β₂*B - r₁*A*B + r₂*C\n    dC = @. α₃ - β₃*C + r₁*A*B - r₂*C\n    cat(dA, dB, dC, dims=3)\nend\n\nWe can build the Symbolics version of this model by tracing the model function:\n\n# Define the initial condition as normal arrays\n@variables u[1:N, 1:N, 1:3]\ndu = simplify.(f(collect(u), nothing, 0.0))\nvec(du)[1:10]\n\nThe output, here the in-place modified du, is a symbolic representation of each output of the function. We can then utilize this in the Symbolics functionality. For example, let's build a parallel version of f first:\n\nfastf = eval(Symbolics.build_function(du,u,\n            parallel=Symbolics.MultithreadedForm())[2])\n\nNow let's compute the sparse Jacobian function and compile a fast multithreaded version:\n\njac = Symbolics.sparsejacobian(vec(du), vec(u))\nrow,col,val = findnz(jac)\nscatter(row,col,legend=false,ms=1,c=:black)\n\nfjac = eval(Symbolics.build_function(jac,u,\n            parallel=Symbolics.MultithreadedForm())[2])\n\nIt takes awhile for this to generate, but the results will be worth it! Now let's set up the parabolic PDE to be solved by DifferentialEquations.jl. We will set up the vanilla version and the sparse multithreaded version:\n\nusing OrdinaryDiffEq\nu0 = zeros(N, N, 3)\nMyA = zeros(N, N);\nAMx = zeros(N, N);\nDA = zeros(N, N);\nprob = ODEProblem(f, u0, (0.0, 10.0))\nfastprob = ODEProblem(ODEFunction((du, u, p, t) -> fastf(du, u),\n                                   jac = (du, u, p, t) -> fjac(du, u),\n                                   jac_prototype = similar(jac, Float64)),\n                                   u0, (0.0, 10.0))\n\nLet's see the timing difference:\n\nusing BenchmarkTools\n#@btime solve(prob, TRBDF2()); # 33.073 s (895404 allocations: 23.87 GiB)\n#warning the following solve takes a long time to compile, but afterwards is very fast.\n#@btime solve(fastprob, TRBDF2()); # 209.670 ms (8208 allocations: 109.25 MiB)\n\nBoom, an automatic 157x acceleration that grows as the size of the problem increases!","category":"section"},{"location":"manual/io/#I/O,-Saving,-and-Latex","page":"I/O, Saving, and Latex","title":"I/O, Saving, and Latex","text":"Note that Julia's standard I/O functionality can be used to save Symbolics expressions out to files. For example, here we will generate an in-place version of f and save the anonymous function to a .jl file:\n\nusing Symbolics\n@variables u[1:3]\nfunction f(u)\n  [u[1]-u[3],u[1]^2-u[2],u[3]+u[2]]\nend\nex1, ex2 = build_function(f(u),u)\nwrite(\"function.jl\", string(ex2))\n\nNow we can do something like:\n\ng = include(\"function.jl\")\n\nand that will load the function back in. Note that this can be done to save the transformation results of Symbolics.jl so that they can be stored and used in a precompiled Julia package.","category":"section"},{"location":"manual/io/#Latexification","page":"I/O, Saving, and Latex","title":"Latexification","text":"Symbolics.jl's expressions support Latexify.jl, and thus\n\nusing Latexify\nlatexify(ex)\n\nwill produce LaTeX output from Symbolics models and expressions. This works on basics like Term all the way to higher primitives like ODESystem and ReactionSystem.","category":"section"},{"location":"manual/solver/#symbolic_solver","page":"Solving Symbolic Equations","title":"Solving Symbolic Equations","text":"The main symbolic solver for Symbolics.jl is symbolic_solve. Symbolic solving means that it only uses symbolic (algebraic) methods and outputs exact solutions.\n\nOne other symbolic solver is symbolic_linear_solve which is limited compared to  symbolic_solve as it only solves linear equations.\n\nsymbolic_solve only supports symbolic, i.e. non-floating point computations, and thus prefers equations where the coefficients are integer, rational, or symbolic. Floating point coefficients are transformed into rational values and BigInt values are used internally with a potential performance loss, and thus it is recommended that this functionality is only used with floating point values if necessary. In contrast, symbolic_linear_solve directly handles floating point values using standard factorizations.","category":"section"},{"location":"manual/solver/#More-technical-details-and-examples","page":"Solving Symbolic Equations","title":"More technical details and examples","text":"","category":"section"},{"location":"manual/solver/#Technical-details","page":"Solving Symbolic Equations","title":"Technical details","text":"The symbolic_solve function uses 4 hidden solvers in order to solve the user's input. Its base, solve_univar, uses analytic solutions up to polynomials of degree 4 and factoring as its method for solving univariate polynomials. The function's solve_multipoly uses GCD on the input polynomials then throws passes the result to solve_univar. The function's solve_multivar uses Groebner basis and a separating form in order to create linear equations in the input variables and a single high degree equation in the separating variable [1]. Each equation resulting from the basis is then passed to solve_univar. We can see that essentially, solve_univar is the building block of symbolic_solve. If the input is not a valid polynomial and can not be solved by the algorithm above, symbolic_solve passes it to ia_solve, which attempts solving by attraction and isolation [2]. This only works when the input is a single expression and the user wants the answer in terms of a single variable. Say log(x) - a == 0 gives us [e^a].","category":"section"},{"location":"manual/solver/#Nice-examples","page":"Solving Symbolic Equations","title":"Nice examples","text":"using Symbolics, Nemo;\n@variables x;\nSymbolics.symbolic_solve(9^x + 3^x ~ 8, x)\n\n@variables x y z;\nSymbolics.symbolic_linear_solve(2//1*x + y - 2//1*z ~ 9//1*x, 1//1*x)\n\nusing Groebner;\n@variables x y z;\n\neqs = [x^2 + y + z - 1, x + y^2 + z - 1, x + y + z^2 - 1]\nSymbolics.symbolic_solve(eqs, [x,y,z])","category":"section"},{"location":"manual/solver/#SymPy-Integration","page":"Solving Symbolic Equations","title":"SymPy Integration","text":"SymPy also includes solves as well, and the SymPy.jl extensions allow for automatically converting Symbolics expressions for use in its solvers.","category":"section"},{"location":"manual/solver/#Feature-completeness","page":"Solving Symbolic Equations","title":"Feature completeness","text":"[x] Linear and polynomial equations\n[x] Systems of linear and polynomial equations\n[x] Some transcendental functions\n[x] Systems of linear equations with parameters (via symbolic_linear_solve)\n[ ] Equations with radicals\n[x] Systems of polynomial equations with parameters and positive dimensional systems\n[ ] Inequalities","category":"section"},{"location":"manual/solver/#Expressions-we-can-not-solve-(but-aim-to)","page":"Solving Symbolic Equations","title":"Expressions we can not solve (but aim to)","text":"# Mathematica\n\nIn[1]:= Reduce[x^2 - x - 6 > 0, x]\nOut[1]= x < -2 || x > 3\n\nIn[2]:= Reduce[x+a > 0, x]\nOut[2]= a \\[Element] Reals && x > -a\n\nIn[3]:= Solve[x^(x)  + 3 == 0, x]\nOut[3]= {{x -> (I \\[Pi] + Log[3])/ProductLog[I \\[Pi] + Log[3]]}}","category":"section"},{"location":"manual/solver/#References","page":"Solving Symbolic Equations","title":"References","text":"[1]: Rouillier, F. Solving Zero-Dimensional Systems Through the Rational Univariate Representation. AAECC 9, 433–461 (1999).\n\n[2]: R. W. Hamming, Coding and Information Theory, ScienceDirect, 1980.","category":"section"},{"location":"manual/solver/#Symbolics.symbolic_solve","page":"Solving Symbolic Equations","title":"Symbolics.symbolic_solve","text":"symbolic_solve(expr, x; dropmultiplicity=true, warns=true)\n\nsymbolic_solve is a function which attempts to solve input equations/expressions symbolically using various methods.\n\nArguments\n\nexpr: Could be a single univar expression in the form of a poly or multiple univar expressions or multiple multivar polys or a transcendental nonlinear function.\nx: Could be a single variable or an array of variables which should be solved\ndropmultiplicity (optional): Should the output be printed n times where n is the number of occurrence of the root? Say we have (x+1)^2, we then have 2 roots x = -1, by default the output is [-1], If dropmultiplicity is inputted as false, then the output is [-1, -1].\nwarns (optional): When invalid expressions or cases are inputted, should the solver warn you of such cases before returning nothing? if this is set to false, the solver returns nothing. By default, warns are set to true.\n\nSupported input\n\nThe base solver (symbolic_solve) has multiple solvers which chooses from depending on the the type of input (multiple/uni var and multiple/single expression) only after ensuring that the input is valid.\n\nThe expressions inputted can contain parameters, which are assumed to be transcendental. A parameter \"a\" is transcendental if there exists no polynomial P with rational coefficients such that P(a) = 0. Check the examples section.\n\nCurrently, symbolic_solve supports\n\nLinear and polynomial equations (with parameters)\nSystems of linear and polynomials equations (without extra parameters, for now)\nEquations with transcendental functions (with parameters)\n\nExamples\n\nsolve_univar (uses factoring and analytic solutions up to degree 4)\n\nnote: Note\nThe package Nemo is needed in order to use solve_univar as well as solve_multipoly, so executing using Nemo as you will see in the following examples is necessary; otherwise, the function will throw an error.\n\njulia> using Symbolics, Nemo;\n\njulia> @variables x a b;\n\njulia> expr = expand((x + b)*(x^2 + 2x + 1)*(x^2 - a))\n-a*b - a*x - 2a*b*x - 2a*(x^2) + b*(x^2) + x^3 - a*b*(x^2) - a*(x^3) + 2b*(x^3) + 2(x^4) + b*(x^4) + x^5\n\njulia> symbolic_solve(expr, x)\n4-element Vector{Any}:\n -1\n   -b\n   (1//2)*√(4a)\n   (-1//2)*√(4a)\n\njulia> symbolic_solve(expr, x, dropmultiplicity=false)\n5-element Vector{Any}:\n -1\n -1\n   -b\n   (1//2)*√(4a)\n   (-1//2)*√(4a)\n\njulia> symbolic_solve(x^2 + a*x + 6, x)\n2-element Vector{SymbolicUtils.BasicSymbolic{Real}}:\n (1//2)*(-a + √(-24 + a^2))\n (1//2)*(-a - √(-24 + a^2))\n\njulia> symbolic_solve(x^7 - 1, x)\n2-element Vector{Any}:\n  roots_of((1//1) + x + x^2 + x^3 + x^4 + x^5 + x^6, x)\n 1\n\nsolve_multivar (uses Groebner basis and solve_univar to find roots)\n\nnote: Note\nSimilar to solve_univar, Groebner is needed for solve_multivar or to be fully functional.\n\njulia> using Groebner\n\njulia> @variables x y z\n3-element Vector{Num}:\n x\n y\n z\n\njulia> eqs = [x+y^2+z, z*x*y, z+3x+y]\n3-element Vector{Num}:\n x + z + y^2\n       x*y*z\n  3x + y + z\n\njulia> symbolic_solve(eqs, [x,y,z])\n3-element Vector{Any}:\n Dict{Num, Any}(z => 0, y => 1//3, x => -1//9)\n Dict{Num, Any}(z => 0, y => 0, x => 0)\n Dict{Num, Any}(z => -1, y => 1, x => 0)\n\nnote: Note\nIf Nemo or Groebner are not imported when needed, the solver throws an error.\n\njulia> using Symbolics\n\njulia> @variables x y z;\n\njulia> symbolic_solve(x+1, x)\nERROR: \"Nemo is required. Execute `using Nemo` to enable this functionality.\"\n\njulia> symbolic_solve([x+1, y], [x, y])\nERROR: \"Groebner bases engine is required. Execute `using Groebner` to enable this functionality.\"\n\nsolve_multipoly (uses GCD between the input polys)\n\njulia> symbolic_solve([x-1, x^3 - 1, x^2 - 1, (x-1)^20], x)\n1-element Vector{BigInt}:\n 1\n\nia_solve (solving by isolation and attraction)\n\njulia> symbolic_solve(2^(x+1) + 5^(x+3), x)\n1-element Vector{SymbolicUtils.BasicSymbolic{Real}}:\n (-slog(2) - log(complex(-1)) + 3slog(5)) / (slog(2) - slog(5))\n\njulia> symbolic_solve(log(x+1)+log(x-1), x)\n2-element Vector{SymbolicUtils.BasicSymbolic{BigFloat}}:\n (1//2)*√(8.0)\n (-1//2)*√(8.0)\n\njulia> symbolic_solve(a*x^b + c, x)\n((-c)^(1 / b)) / (a^(1 / b))\n\nEvaluating output (converting to floats)\n\nIf you want to evaluate the exact expressions found by symbolic_solve, you can do the following:\n\njulia> roots = symbolic_solve(2^(x+1) + 5^(x+3), x)\n1-element Vector{SymbolicUtils.BasicSymbolic{Real}}:\n (-slog(2) - log(complex(-1)) + 3slog(5)) / (slog(2) - slog(5))\n\njulia> Symbolics.symbolic_to_float.(roots)\n1-element Vector{Complex{BigFloat}}:\n -4.512941594732059759689023145584186058252768936052415430071569066192919491762214 + 3.428598090438030380369414618548038962770087500755160535832807433942464545729382im\n\n\n\n\n\n","category":"function"},{"location":"manual/solver/#Symbolics.symbolic_linear_solve","page":"Solving Symbolic Equations","title":"Symbolics.symbolic_linear_solve","text":"symbolic_linear_solve(\n    eq,\n    var;\n    simplify,\n    check\n) -> Union{Nothing, Vector{SymbolicUtils.BasicSymbolicImpl.var\"typeof(BasicSymbolicImpl)\"{SymReal}}}\n\n\nSolve equation(s) eqs for a set of variables vars.\n\nAssumes length(eqs) == length(vars)\n\nCurrently only works if all equations are linear. check if the expr is linear w.r.t vars.\n\nExamples\n\njulia> @variables x y\n2-element Vector{Num}:\n x\n y\n\njulia> Symbolics.symbolic_linear_solve(x + y ~ 0, x)\n-y\n\njulia> Symbolics.symbolic_linear_solve([x + y ~ 0, x - y ~ 2], [x, y])\n2-element Vector{Float64}:\n  1.0\n -1.0\n\n\n\n\n\n","category":"function"},{"location":"manual/solver/#Symbolics.solve_univar","page":"Solving Symbolic Equations","title":"Symbolics.solve_univar","text":"solve_univar(expression, x; dropmultiplicity=true)\n\nThis solver uses analytic solutions up to degree 4 to solve univariate polynomials. It first handles the special case of the expression being of operation ^. E.g. math (x+2)^{20}. We solve this by removing the int 20, then solving the poly math x+2 on its own. If the parameter mult of the solver is set to true, we then repeat the found roots of math x+2 twenty times before returning the results to the user.\n\nStep 2 is filtering the expression after handling this special case, and then factoring it using factor_use_nemo. We then solve all the factors outputted using the analytic methods implemented in the function get_roots and its children.\n\nArguments\n\nexpr: Single symbolics Num or SymbolicUtils.BasicSymbolic expression. This is equated to 0 and then solved. E.g. expr = x+2, we solve x+2 = 0\nx: Single symbolics variable\ndropmultiplicity (optional): Print repeated roots or not?\nstrict (optional): Bool that enables/disables strict assert if input expression is a univariate polynomial or not. If strict=true and expression is not a polynomial, solve_univar throws an assertion error.\n\nExamples\n\n\n\n\n\n","category":"function"},{"location":"manual/solver/#Symbolics.ia_solve","page":"Solving Symbolic Equations","title":"Symbolics.ia_solve","text":"ia_solve(lhs, var; kwargs...)\n\nThis function attempts to solve transcendental functions by first checking the \"smart\" number of occurrences in the input LHS. By smart here we mean that polynomials are counted as 1 occurrence. for example x^2 + 2x is 1 occurrence of x. So we abstract all occurrences of x's as polynomials. Say: log(x+1) + x^2 is seen as log(f(x)) + g(x) so there are 2 occurrences of x. If there is only 1 occurrence of x in an input expression, isolate is called.\n\nIsolate reverses all operations applied on the occurrence of x until we have f(x) = some constant then we can solve this using our polynomial solvers.\n\nIf more than 1 occurrence of x is found, ia_solve attempts to attract the occurrences of x in order to reduce these occurrences to 1. For example, log(x+1) + log(x-1) can be converted to log(x^2 - 1) which now could be isolated using Isolate.\n\nattract(lhs, var) currently uses 4 techniques for attraction.\n\nLog addition: log(f(x)) + log(g(x)) => log(h(x))\nExponential simplification: a*b^(f(x)) + c*d^(g(x)) => f(x) * log(b) - g(x) * log(d) + log(-a/c). And now this is actually 1 occurrence of x since f(x) and g(x) are just multiplied by constants not wrapped in some operation.\nTrig simplification: this bruteforces multiple trig identities and doesn't detect them before hand.\nPolynomialization: as a last resort, attract attempts to polynomialize the expression. Say sin(x+2)^2 + sin(x+2) + 10 is converted to X^2 + X + 10, we then solve this using our polynomial solver, and afterwards, isolate sin(x+2) = the roots found by solve for X^2 + X + 10\n\nAfter attraction, we check the number of occurrences again, and if its 1, we isolate, if not, we throw an error to tell the user that this is currently unsolvable by our covered techniques.\n\nArguments\n\nlhs: a Num/SymbolicUtils.BasicSymbolic\nvar: variable to solve for.\n\nKeyword arguments\n\nwarns = true: Whether to emit warnings for unsolvable expressions.\ncomplex_roots = true: Whether to consider complex roots of x ^ n ~ y, where n is an integer.\nperiodic_roots = true: If true, isolate f(x) ~ y as x ~ finv(y) + n * period where  is_periodic(f) == true, finv = left_inverse(f) and period = fundamental_period(f). n  is a new anonymous symbolic variable.\n\nExamples\n\njulia> solve(a*x^b + c, x)\n((-c)^(1 / b)) / (a^(1 / b))\n\njulia> solve(2^(x+1) + 5^(x+3), x)\n1-element Vector{SymbolicUtils.BasicSymbolic{Real}}:\n (-log(2) + 3log(5) - log(complex(-1))) / (log(2) - log(5))\n\njulia> solve(log(x+1)+log(x-1), x)\n2-element Vector{SymbolicUtils.BasicSymbolic{Real}}:\n (1//2)*RootFinding.ssqrt(8.0)\n (-1//2)*RootFinding.ssqrt(8.0)\n\njulia> expr = sin(x+2)^2 + sin(x+2) + 10\n10 + sin(2 + x) + sin(2 + x)^2\n\njulia> RootFinding.ia_solve(expr, x)\n[ Info: var\"##230\" ϵ Ζ: e.g. 0, 1, 2...\n[ Info: var\"##234\" ϵ Ζ: e.g. 0, 1, 2...\n2-element Vector{SymbolicUtils.BasicSymbolic{Real}}:\n -2 + π*2var\"##230\" + asin((1//2)*(-1 + RootFinding.ssqrt(-39)))\n -2 + π*2var\"##234\" + asin((1//2)*(-1 - RootFinding.ssqrt(-39)))\n\nAll transcendental functions for which left_inverse is defined are supported. To enable ia_solve to handle custom transcendental functions, define an inverse or left inverse. If the function is periodic, is_periodic and fundamental_period must be defined. If the function imposes certain conditions on its input or output (for example, log requires that its input be positive) define ia_conditions!.\n\nSee also: left_inverse, inverse, is_periodic, fundamental_period, ia_conditions!.\n\nReferences\n\n[1]: R. W. Hamming, Coding and Information Theory, ScienceDirect, 1980.\n\n\n\n\n\n","category":"function"},{"location":"manual/solver/#Symbolics.ia_conditions!","page":"Solving Symbolic Equations","title":"Symbolics.ia_conditions!","text":"ia_conditions!(f, lhs, rhs::Vector{Any}, conditions::Vector{Tuple})\n\nIf f is a left-invertible function, lhs and rhs[i] are univariate functions and f(lhs) ~ rhs[i] for all i in eachindex(rhss), push to conditions all the relevant conditions on lhs or rhs[i]. Each condition is of the form (sym, op) where sym is an expression involving lhs and/or rhs[i] and op is a binary relational operator. The condition op(sym, 0) is then required to be true for the equation f(lhs) ~ rhs[i] to be valid.\n\nFor example, if f = log, lhs = x and rhss = [y, z] then the condition x > 0 must be true. Thus, (lhs, >) is pushed to conditions. Similarly, if f = sqrt, rhs[i] >= 0 must be true for all i, and so (y, >=) and (z, >=) will be appended to conditions. \n\n\n\n\n\n","category":"function"},{"location":"manual/solver/#Symbolics.is_periodic","page":"Solving Symbolic Equations","title":"Symbolics.is_periodic","text":"is_periodic(f)\n\nReturn true if f is a single-input single-output periodic function. Return false by default. If is_periodic(f) == true, then fundamental_period(f) must also be defined.\n\nSee also: fundamental_period\n\n\n\n\n\n","category":"function"},{"location":"manual/solver/#Symbolics.fundamental_period","page":"Solving Symbolic Equations","title":"Symbolics.fundamental_period","text":"fundamental_period(f)\n\nReturn the fundamental period of periodic function f. Must only be called if is_periodic(f) == true.\n\nsee also: is_periodic\n\n\n\n\n\n","category":"function"},{"location":"manual/solver/#Symbolics.sympy_linear_solve","page":"Solving Symbolic Equations","title":"Symbolics.sympy_linear_solve","text":"sympy_linear_solve(A, b)\n\nSolves linear system Ax = b using SymPy.\n\nArguments\n\nA: Matrix of Symbolics expressions.\nb: Vector of Symbolics expressions.\n\nReturns\n\nVector of Symbolics solutions.\n\nExample\n\n@variables x y\nA = [1 2; 3 4]\nb = [x, y]\nsol = sympy_linear_solve(A, b)\n\n\n\n\n\n","category":"function"},{"location":"manual/solver/#Symbolics.sympy_algebraic_solve","page":"Solving Symbolic Equations","title":"Symbolics.sympy_algebraic_solve","text":"sympy_algebraic_solve(expr, var)\n\nSolves algebraic equation(s) expr = 0 for var(s) using SymPy.\n\nArguments\n\nexpr: Symbolics expression or vector of expressions for a system of equations (linear or nonlinear).\nvar: Symbolics variable or vector of variables to solve for.\n\nReturns\n\nFor a single equation: List of Symbolics solutions.\nFor a system: List of dictionaries mapping variables to solutions.\n\nExample\n\n@variables x y\n# Single equation\nexpr = x^2 - 4\nsol = sympy_algebraic_solve(expr, x)  # Returns [2, -2]\n# Nonlinear system\neqs = [x^2 + y^2 - 4, x - y]  # Circle and line\nsol = sympy_algebraic_solve(eqs, [x, y])  # Returns [{x=>1, y=>1}, {x=>-1, y=>-1}]\n\n\n\n\n\n","category":"function"},{"location":"manual/misc/#Miscellaneous-API","page":"Miscellaneous API","title":"Miscellaneous API","text":"This page documents various utility functions and constants that don't fit into other categories.","category":"section"},{"location":"manual/misc/#Constants","page":"Miscellaneous API","title":"Constants","text":"","category":"section"},{"location":"manual/misc/#Utility-functions","page":"Miscellaneous API","title":"Utility functions","text":"","category":"section"},{"location":"manual/misc/#Symbolics.linear_expansion","page":"Miscellaneous API","title":"Symbolics.linear_expansion","text":"(a, b, islinear) = linear_expansion(t, x)\n\nWhen islinear, return a and b such that a * x + b == t. Instead of calling linear_expansion multiple times with the same x, prefer using Symbolics.LinearExpander.\n\n\n\n\n\n","category":"function"},{"location":"manual/misc/#Symbolics.LinearExpander","page":"Miscellaneous API","title":"Symbolics.LinearExpander","text":"struct LinearExpander\n\nA functor which acts as the workhorse for Symbolics.linear_expansion. The operation linear_expansion(t::Symbolics.SymbolicT, x::Symbolics.SymbolicT) can equivalently be phrased as LinearExpander(x)(t). This functor caches data during processing, and thus several linear_expansion calls with the same x can be rephrased as multiple calls to LinearExpansion(x). This can help avoid repeated computation and allocations.\n\n\n\n\n\n","category":"type"},{"location":"tutorials/converting_to_C/#Automatic-Conversion-of-Julia-Code-to-C-Functions","page":"Automatic Conversion of Julia Code to C Functions","title":"Automatic Conversion of Julia Code to C Functions","text":"Since Symbolics.jl can trace Julia code into Symbolics IR that can be built and compiled via build_function to C, this gives us a nifty way to automatically generate C functions from Julia code! To see this in action, let's start with the Lotka-Volterra equations:\n\nusing Symbolics\nfunction lotka_volterra!(du, u, p, t)\n  x, y = u\n  α, β, δ, γ = p\n  du[1] = dx = α*x - β*x*y\n  du[2] = dy = -δ*y + γ*x*y\nend\n\nNow we trace this into Symbolics:\n\n@variables t du[1:2] u[1:2] p[1:4]\ndu = collect(du)\nlotka_volterra!(du, u, p, t)\ndu\n\nand then we build the function:\n\nbuild_function(du, u, p, t, target=Symbolics.CTarget())\n\nIf we want to compile this, we do expression=Val{false}:\n\nf = build_function(du, u, p, t, target=Symbolics.CTarget(), expression=Val{false})\n\nnow we check it computes the same thing:\n\ndu = rand(2); du2 = rand(2)\nu = rand(2)\np = rand(4)\nt = rand()\nf(du, u, p, t)\nlotka_volterra!(du2, u, p, t)\ndu == du2 # true!","category":"section"},{"location":"manual/structs/#Symbolic-Structs","page":"Symbolic Structs","title":"Symbolic Structs","text":"It is occasionally useful to represent structs symbolically, and retain the ability to perform getproperty on them. For example, let us consider the following struct representing a point in 2D cartesian coordinates.\n\nusing Symbolics, SymbolicUtils\n\nstruct Point2D{T}\n    x::T\n    y::T\nend\n\nTo allow this struct to be used symbolically, the @symstruct macro must be used:\n\n@symstruct Point2D{T}\n\nNote that this macro requires that all type parameters of the struct be present in the macro use. With this, we can create symbolic structs like any other variable:\n\n@variables point::Point2D{Real}\ntypeof(point)\n@assert point.x isa Num\n@assert point.y isa Num\n\nSubsequently, fields of the struct can be accessed symbolically:\n\npoint.x^2 + point.y^2","category":"section"},{"location":"manual/structs/#Array-fields","page":"Symbolic Structs","title":"Array fields","text":"What if we have a general point type capable of representing arbitrary dimensional cartesian coordinates?\n\nstruct PointN{T, N}\n    x::Vector{T}\n\n    function PointN{T, N}(x::Vector{T}) where {T, N}\n        @assert length(x) == N\n        new{T, N}(x)\n    end\nend\n\nThe standard @symstruct PointN{T, N} would work. However, Symbolics cannot infer the length of field x simply from the type PointN{T, N}. As a result, the field would be inferred as an unknown length vector, and allow arbitrary indexing such as point.x[1234]. To provide this information, the @symstruct macro allows specifying additional metadata:\n\n@symstruct PointN{T, N} begin\n    shape(:x) = (1:N,)\nend\n\nThe shape option allows specifying the shape of array fields. Here, we're saying that the shape of field :x is (1:N,) (i.e. it is a 1-indexed vector of length N). The expression can use type information of the registered struct type. The specific details of all options are documented in the @symstruct macro. With the above declaration, we can now have safe symbolic PointN.\n\n@variables point::PointN{Real, 3}\npoint.x[1]^2 + point.x[2]^2 + point.x[3]^2\n@assert size(point.x) == (3,)\ntry\n    point.x[4]\ncatch e\n    Base.showerror(e)\nend","category":"section"},{"location":"manual/structs/#Abstract-types","page":"Symbolic Structs","title":"Abstract types","text":"Often, it is useful to specify that all subtypes of a given abstract type should be considered symbolic structs. The @symstruct macro can be used on abstract types to enable this behavior.\n\nabstract type AbstractRecord{T} end\n\nstruct Record1{T} <: AbstractRecord{T}\n    x::Vector{T}\n    y::T\nend\n\nstruct Record2{T} <: AbstractRecord{T}\n    x::Vector{T}\n    z::T\nend\n\n@symstruct AbstractRecord{T} begin\n    shape(:x) = (1:3,)\nend\n\nAs evidenced above, even options such as shape can be specified for abstract types. These are applicable to all subtypes.\n\n@variables rec1::Record1{Real} rec2::Record2{Real}\n@assert size(rec1.x) == (3,)\n@assert size(rec2.x) == (3,)\nrec1.x[1] + rec2.x[2] + rec1.y + rec2.z\n\nThe @symstruct macro roughly follows Julia subtyping behavior. This means that more specific @symstruct declarations override less specific ones.\n\nstruct Record3{T} <: AbstractRecord{T}\n    x::Vector{T}\n    w::T\nend\n\n@symstruct Record3{T} begin\n    shape(:x) = (1:4,)\nend\n\nstruct Record4{T} <: AbstractRecord{T}\n    x::Vector{T}\n    f::Vector{T}\nend\n\n@symstruct Record4{T} begin\n    shape(:f) = (1:5,)\nend\n\n@variables rec3::Record3{Real} rec4::Record4{Real}\n@assert size(rec3.x) == (4,) # Different from the one declared by `AbstractRecord`\n@assert size(rec4.x) == (3,) # Falls back to the `AbstractRecord` definition\n@assert size(rec4.f) == (5,) # Uses the more specific declaration","category":"section"},{"location":"manual/structs/#Arrays-of-symbolic-structs","page":"Symbolic Structs","title":"Arrays of symbolic structs","text":"Arrays of symbolic structs are required to have a concrete eltype\n\n@variables pts[1:3]::PointN{Real, 3}\npts[1].x[1] + pts[2].x[2]","category":"section"},{"location":"manual/structs/#Nested-structs","page":"Symbolic Structs","title":"Nested structs","text":"Symbolic struct types can be nested inside each other.\n\n@variables recs::Record1{Record1{Real}}\nrecs.x[1].x[1] + recs.x[2].y.y","category":"section"},{"location":"manual/structs/#Registered-functions-of-symbolic-structs","page":"Symbolic Structs","title":"Registered functions of symbolic structs","text":"There is some unique behavior when registering functions where arguments are (arrays of) symbolic structs. The @symstruct macro works by defining some interface functions to allow using the Symbolics.SymStruct wrapper type, similar to how Num is a wrapper type. All registration functions behave the same as they did prior to this feature if the SymStruct is unwrapped (using SymbolicUtils.unwrap). The difference in behavior arises from how wrapped SymStruct types are handled. In general, the @register_symbolic and @register_array_symbolic macros can only use information from the provided type annotations. They cannot know to declare methods for SymStruct{ConcreteFoo} if the function is registered with AbstractFoo. For example, the following syntax:\n\n@register_symbolic foofn(foo::AbstractFoo)\n\nWill only work for a variable declared as @variables foo::ConcreteFoo if @symstruct AbstractFoo is declared, regardless of whether @symstruct ConcreteFoo is declared or not. This will always work for @variables afoo::AbstractFoo.\n\n@register_symbolic foofn2(foos::Vector{AbstractFoo})\n\nSuppose we have declared @variables a::ConcreteFoo b::ConcreteFoo cs[1:3]::ConcreteFoo. foofn2([a, b]) will work only if @symstruct AbstractFoo is declared, regardless of whether @symstruct ConcreteFoo is declared or not. The same applies for foofn2(cs).\n\nIf you are not using symbolic structs, the registration macros behave exactly as they did prior to this feature.","category":"section"},{"location":"manual/structs/#API","page":"Symbolic Structs","title":"API","text":"","category":"section"},{"location":"manual/structs/#Symbolics.@symstruct","page":"Symbolic Structs","title":"Symbolics.@symstruct","text":"@symstruct Foo{T1, T2, ...}\n@symstruct Foo{T1, T2, ...} begin\n  # options...\nend\n\nA macro which enables using type Foo with SymStruct as a symbolic struct. The first argument to the macro must be the struct type, with all type parameters named. The optional second argument is an optional begin..end block containing options that influence the behavior of the macro. The following options are allowed:\n\nshape(:field) = # expression. For array fields, the shape of the field cannot be inferred from the type. In case the type of the field can be inferred from the type, it can be specified using this syntax. The expression must evaluate to an object of type Union{SymbolicUtils.Unknown, AbstractVector{UnitRange{Int}}, Tuple{Vararg{UnitRange{Int}}}}. The expression has access to the concrete type of the struct being accessed, with all type parameters available as declared in the first argument.\n\nFor example, given the following struct:\n\nstruct Record{T}\n  x::Int\n  y::Real\n  z::T\nend\n\nIt can be registered as\n\n# Note: the type parameter must be declared, but the name itself does not matter\n@symstruct Record{V} begin\n# If `V` is an `AbstractVector` then field `z` is a 3-vector. Otherwise, it is a scalar.\n  shape(:z) = V <: AbstractVector ? [1:3] : ()\nend\n\nNow,\n\n@variables rec::Record{Int} rec2::Record{Vector{Int}}\n\nrec.x, rec2.x will be Nums with symtype Int. rec.y and rec2.y will be Nums with symtype Real. rec.z will be a Num with symtype Int. rec2.z will be an Arr{Num, 1} with symtype Vector{Int} and shape [1:2].\n\nIn case the shape of a field is not provided, it will be inferred from the type. For AbstractArray subtypes, it will be SymbolicUtils.Unknown(ndims(arr_type)). Otherwise, it will be treated as a scalar.\n\n\n\n\n\n","category":"macro"},{"location":"manual/structs/#Symbolics.SymStruct","page":"Symbolic Structs","title":"Symbolics.SymStruct","text":"struct SymStruct{T}\n\nWrapper type for symbolic structs. Requires that the wrapped struct type T be registered with @symstruct. After registration, @variables can be used to create the symbolic struct.\n\n# Here, `record` has type `SymStruct{Record}`\n@variables record::Record\n\ngetproperty access on this is a symbolic operation, and returns an expression performing the appropriate field access. This can only wrap concrete struct types (isconcretetype(T) must be true). getproperty on this struct leverages fieldnames and fieldtypes. Thus, will thus not respect custom getproperty methods on the wrapped struct type.\n\n\n\n\n\n","category":"type"},{"location":"manual/build_function/#Function-Building-and-Compilation-(build_function)","page":"Function Building and Compilation (build_function)","title":"Function Building and Compilation (build_function)","text":"At any time, callable functions can be generated from Symbolics IR by using Symbolics.toexpr. This performs some cleaning to return an expression without extraneous pieces that commonly matches expressions one would write in functions like those for differential equation solvers and optimization libraries. These functions can be automatically parallelized and specialize on Julia types like static arrays and sparse matrices.\n\nThe core compilation process of Symbolics IR is build_function. build_function takes an operation or an AbstractArray of operations and generates a compilable version of the model for numerical solvers. The form of this output is dependent on the target. By default, the target outputs Julia code, but other formats, such as C, Stan, and MATLAB are available. These can be generated as expressions which can then be evaluated into a callable function, or the compilers for the respective targets can be invoked to directly give back the function handle.","category":"section"},{"location":"manual/build_function/#build_function","page":"Function Building and Compilation (build_function)","title":"build_function","text":"","category":"section"},{"location":"manual/build_function/#Target-Specific-Definitions","page":"Function Building and Compilation (build_function)","title":"Target-Specific Definitions","text":"","category":"section"},{"location":"manual/build_function/#Limitations","page":"Function Building and Compilation (build_function)","title":"Limitations","text":"build_function ","category":"section"},{"location":"manual/build_function/#Symbolics.build_function","page":"Function Building and Compilation (build_function)","title":"Symbolics.build_function","text":"build_function(ex, args...;\n               expression = Val{true},\n               target = JuliaTarget(),\n               parallel=nothing,\n               kwargs...)\n\nGenerates a numerically-usable function from a Symbolics Num.\n\nArguments:\n\nex: The Num to compile\nargs: The arguments of the function\nexpression: Whether to generate code or whether to generate the compiled form. By default, expression = Val{true}, which means that the code for the function is returned. If Val{false}, then the returned value is compiled.\n\nKeyword Arguments:\n\ntarget: The output target of the compilation process. Possible options are:\nJuliaTarget: Generates a Julia function\nCTarget: Generates a C function\nStanTarget: Generates a function for compiling with the Stan probabilistic programming language\nMATLABTarget: Generates an anonymous function for use in MATLAB and Octave environments\nparallel: The kind of parallelism to use in the generated function. Defaults to SerialForm(), i.e. no parallelism, if ex is a single expression or an array containing <= 1500 non-zero expressions. If ex is an array of > 1500 non-zero expressions, then ShardedForm(80, 4) is used. See below for more on ShardedForm. Note that the parallel forms are not exported and thus need to be chosen like Symbolics.SerialForm(). The choices are:\nSerialForm(): Serial execution.\nShardedForm(cutoff, ncalls): splits the output function into sub-functions  which contain at most cutoff number of output rhss. These sub-functions  are called by the top-level function that buildfunction returns.  This helps in reducing the compile time of the generated function.\nMultithreadedForm(): Multithreaded execution with a static split, evenly splitting the number of expressions per thread.\nfname: Used by some targets for the name of the function in the target space.\n\nNote that not all build targets support the full compilation interface. Check the individual target documentation for details.\n\n\n\n\n\n","category":"function"},{"location":"manual/build_function/#Symbolics._build_function-Tuple{Symbolics.JuliaTarget, AbstractArray, Vararg{Any}}","page":"Function Building and Compilation (build_function)","title":"Symbolics._build_function","text":"_build_function(target::JuliaTarget, rhss::AbstractArray, args...;\n                   conv=toexpr,\n                   expression = Val{true},\n                   expression_module = @__MODULE__(),\n                   checkbounds = false,\n                   postprocess_fbody=ex -> ex,\n                   linenumbers = false,\n                   outputidxs=nothing,\n                   skipzeros = false,\n                   force_SA = false,\n                   wrap_code = (nothing, nothing),\n                   fillzeros = skipzeros && !(rhss isa SparseMatrixCSC),\n                   states = LazyState(),\n                   iip_config = (true, true),\n                   parallel=nothing, cse = false, kwargs...)\n\nBuild function target: JuliaTarget\n\n_build_function(target::JuliaTarget, rhss, args...;\n                conv = toexpr,\n                expression = Val{true},\n                checkbounds = false,\n                linenumbers = false,\n                headerfun = addheader, outputidxs=nothing,\n                convert_oop = true, force_SA = false,\n                skipzeros = outputidxs===nothing,\n                fillzeros = skipzeros && !(typeof(rhss)<:SparseMatrixCSC),\n                parallel=SerialForm(), kwargs...)\n\nGenerates a Julia function which can then be utilized for further evaluations. If expression=Val{false}, the return is a Julia function which utilizes RuntimeGeneratedFunctions.jl to be free of world-age issues.\n\nIf the rhss is a scalar, the generated function is a function with a scalar output. Otherwise, if it's an AbstractArray, the output is two functions, one for out-of-place AbstractArray output and a second which is a mutating function. The outputted functions match the given argument order, i.e., f(u,p,args...) for the out-of-place and scalar functions and f!(du,u,p,args..) for the in-place version.\n\nSpecial Keyword Arguments:\n\nparallel: The kind of parallelism to use in the generated function. Defaults to SerialForm(), i.e. no parallelism. Note that the parallel forms are not exported and thus need to be chosen like Symbolics.SerialForm(). The choices are:\nSerialForm(): Serial execution.\nShardedForm(cutoff, ncalls): splits the output function into sub-functions  which contain at most cutoff number of output rhss. These sub-functions  are called by the top-level function that buildfunction returns.\nMultithreadedForm(): Multithreaded execution with a static split, evenly splitting the number of expressions per thread.\nconv: The conversion function of symbolic types to Expr. By default, this uses the toexpr function.\ncheckbounds: For whether to enable bounds checking inside the generated function. Defaults to false, meaning that @inbounds is applied.\nlinenumbers: Determines whether the generated function expression retains the line numbers. Defaults to true.\nconvert_oop: Determines whether the OOP version should try to convert the output to match the type of the first input. This is useful for cases like LabelledArrays or other array types that carry extra information. Defaults to true.\nforce_SA: Forces the output of the OOP version to be a StaticArray. Defaults to false, and outputs a static array when the first argument is a static array.\nsimilarto: An AbstractArray subtype which controls the type of the returned array for the OOP version. If provided, it ignores the value of force_SA.\nskipzeros: Whether to skip filling zeros in the in-place version if the filling function is 0.\nfillzeros: Whether to perform fill(out,0) before the calculations to ensure safety with skipzeros.\n\n\n\n\n\n","category":"method"},{"location":"manual/build_function/#Symbolics._build_function-Tuple{Symbolics.CTarget, Array{<:Equation}, Vararg{Any}}","page":"Function Building and Compilation (build_function)","title":"Symbolics._build_function","text":"Build function target: CTarget\n\n_build_function(target::CTarget, eqs::Array{<:Equation}, args...;\n                conv = toexpr, expression = Val{true},\n                fname = :diffeqf,\n                lhsname=:du,rhsnames=[Symbol(\"RHS$i\") for i in 1:length(args)],\n                libpath=tempname(), compiler=:gcc)\n\nThis builds an in-place C function. Only works on arrays of equations. If expression == Val{false}, then this builds a function in C, compiles it, and returns a lambda to that compiled function. These special keyword arguments control the compilation:\n\nlibpath: the path to store the binary. Defaults to a temporary path.\ncompiler: which C compiler to use. Defaults to :gcc, which is currently the only available option.\n\n\n\n\n\n","category":"method"},{"location":"manual/build_function/#Symbolics._build_function-Tuple{Symbolics.StanTarget, Array{<:Equation}, Any, Any, Any}","page":"Function Building and Compilation (build_function)","title":"Symbolics._build_function","text":"Build function target: StanTarget\n\n_build_function(target::StanTarget, eqs::Array{<:Equation}, vs, ps, iv;\n                conv = toexpr, expression = Val{true},\n                fname = :diffeqf, lhsname=:internal_var___du,\n                rhsnames=[:internal_var___u,:internal_var___p,:internal_var___t])\n\nThis builds an in-place Stan function compatible with the Stan differential equation solvers. Unlike other build targets, this one requires (vs, ps, iv) as the function arguments. Only allowed on arrays of equations.\n\n\n\n\n\n","category":"method"},{"location":"manual/build_function/#Symbolics._build_function-Tuple{Symbolics.MATLABTarget, Array{<:Equation}, Vararg{Any}}","page":"Function Building and Compilation (build_function)","title":"Symbolics._build_function","text":"Build function target: MATLABTarget\n\n_build_function(target::MATLABTarget, eqs::Array{<:Equation}, args...;\n                conv = toexpr, expression = Val{true},\n                lhsname=:internal_var___du,\n                rhsnames=[:internal_var___u,:internal_var___p,:internal_var___t])\n\nThis builds an out of place anonymous function @(t,rhsnames[1]) to be used in MATLAB. Compatible with the MATLAB differential equation solvers. Only allowed on expressions, and arrays of expressions.\n\n\n\n\n\n","category":"method"},{"location":"manual/arrays/#symbolic_arrays","page":"Symbolic Arrays","title":"Symbolic Arrays","text":"","category":"section"},{"location":"manual/arrays/#Symbolic-Arrays-vs-Arrays-of-Symbolic-Expressions","page":"Symbolic Arrays","title":"Symbolic Arrays vs Arrays of Symbolic Expressions","text":"Symbolics.jl contains two forms for handling symbolic arrays:\n\nArrays of symbolic expressions: these are Julia arrays with Symbolics.jl objects in them.\nSymbolic Arrays: these are symbolic (O(1)) representations of arrays.\n\nArrays of symbolic expressions are simply Symbolics.jl objects put into Julia arrays. For example:\n\nusing Symbolics\n@variables x y\nu = [x,y]\n\nis a vector of two symbolic variables. As shorthand,\n\nu2 = Symbolics.variables(:x, 1:3, 3:6)\n\ncreates a Julia matrix of symbolic variables. Indexing u or u2 gives symbolic values which act as a normal scalar symbolic value. This form these uses Julia's array functionality and performs symbolic operations on the scalar values.\n\nOn the otherhand, Julia's symbolic array form is an O(1) representation of the whole array.\n\n@variables A[1:5, 1:3]\n\nWhen using this form, A[1,1] is not a symbolic variable but a symbolic expression for indexing the variable A. This representation holds linear algebra expressions in a non-expanded form. For example:\n\n@variables B[1:3, 1:3]\nA * B\n\nin comparison to:\n\na = Symbolics.variables(:a, 1:5, 1:3)\nb = Symbolics.variables(:b, 1:3, 1:3)\na * b\n\nThis makes the symbolic array form much more efficient, but requires that the expressions uses things with registered symbolic array functions which currently has much lower coverage. Also, there are many fallbacks for which arrays of symbolics which makes this approach more accessible but with larger expressions.\n\nWe recommend defaulting to arrays of symbolics unless you need the expression symplifications of the symbolic array approach.","category":"section"},{"location":"manual/arrays/#Using-Symbolic-Arrays","page":"Symbolic Arrays","title":"Using Symbolic Arrays","text":"Symbolic array-valued expressions (symbolic arrays) are supported by Symbolics. Symbolic array expressions propagate useful metadata that depends on input arrays: array dimension, element type and shape.\n\nYou can create a symbolic array variable with the following syntax:\n\nusing Symbolics\n@variables A[1:5, 1:3] b[1:3]\n\nHere, A is a symbolic matrix of size (5, 3) and b is a symbolic vector of length 3.\n\nsize(A)\n\nsize(b)\n\nndims(A)\n\nndims(b)\n\neltype(A)\n\neltype(b)","category":"section"},{"location":"manual/arrays/#Array-operations","page":"Symbolic Arrays","title":"Array operations","text":"Operations on symbolic arrays return symbolic array expressions:\n\nc = A * b\n\nsize(c)\n\neltype(c)\n\nAdjoints, matrix-matrix, and matrix-vector multiplications are supported. Dot product returns a scalar-valued expression:\n\nb'b\n\nsize(b'b)\n\nOuter product returns a matrix:\n\nb * b'\n\nsize(b*b')\n\nTensor or Einstein notation can also be used for array operations using the @arrayop macro. For example, a matrix-vector product can be written as:\n\njulia> d = Symbolics.@arrayop (i,) A[i,j]*b[j]\n@arrayop(_[i] := A[i, j]*b[j])\n\nThese array operations are computed lazily:\n\njulia> c = A*b\n(A*b)[1:5]\n\njulia> isequal(collect(c), collect(d))\ntrue\n\nThis can be useful for vector calculus operations such as the gradient of a vector expression:\n\njulia> @variables x y;\n\njulia> V = [sin(x), x^2 + y]\n2-element Vector{Num}:\n  sin(x)\n y + x^2\n\njulia> D = Differential.([x,y]);\njulia> expand_derivatives.(collect(Symbolics.@arrayop (i,j) D[i](V[j])))\n2×2 Matrix{Num}:\n cos(x)  2x\n      0   1\n\nor the divergence of a vector expression:\n\njulia> expand_derivatives.(collect(Symbolics.@arrayop () D[i](V[i])))\n1 + cos(x)","category":"section"},{"location":"manual/arrays/#Broadcast,-map-and-reduce","page":"Symbolic Arrays","title":"Broadcast, map and reduce","text":"A .* b'\n\nmap(asin, (A*b))\n\n#sum(A) #latexify not working\n\ntypeof(sum(A))\n\ntypeof(sum(A, dims=2))","category":"section"},{"location":"manual/arrays/#Indexing-and-delayed-computation","page":"Symbolic Arrays","title":"Indexing and delayed computation","text":"Indexing array expressions is fairly flexible in Symbolics. Let's go through all the possible ways to index arrays.","category":"section"},{"location":"manual/arrays/#Scalar-indexing-and-scalarization","page":"Symbolic Arrays","title":"Scalar indexing and scalarization","text":"AAt = A*A'\n\nAAt[2,3]\n\nHere we indexed for the element (2,3), but we got back a symbolic indexing expression. You may want to force the element to be computed in terms of the elements of A. This can be done, using the scalarize function.\n\nSymbolics.scalarize(AAt[2,3])\n\n@syms i::Int j::Int\nSymbolics.scalarize(AAt[i,j])\n\nIn general, any scalar expression which is derived from array expressions can be scalarized.\n\n#sum(A[:,1]) + sum(A[2,:])#latexify not working\n\nSymbolics.scalarize(sum(A[:,1]) + sum(A[2,:]))","category":"section"},{"location":"manual/arrays/#Array-API-Reference","page":"Symbolic Arrays","title":"Array API Reference","text":"","category":"section"},{"location":"manual/arrays/#SymbolicUtils.scalarize","page":"Symbolic Arrays","title":"SymbolicUtils.scalarize","text":"scalarize(\n    x::SymbolicUtils.BasicSymbolicImpl.var\"typeof(BasicSymbolicImpl)\"{T}\n) -> Any\nscalarize(\n    x::SymbolicUtils.BasicSymbolicImpl.var\"typeof(BasicSymbolicImpl)\"{T},\n    ::Val{toplevel}\n) -> Any\n\n\nConvert a symbolic expression with array operations into a fully scalarized form. This function expands array operations into element-wise operations, converting symbolic array expressions into arrays of scalar symbolic expressions.\n\nFor ArrayOp expressions, this function reduces eliminated indices and substitutes concrete values for output indices to generate scalar expressions for each array element.\n\nArguments\n\nx::BasicSymbolic{T}: The symbolic expression to scalarize.\n::Val{toplevel}=Val{false}(): Whether to evaluate constant expressions at the top level. When true, constant subexpressions are evaluated; when false, they are recursively scalarized.\n\nReturns\n\nThe scalarized expression. For array-shaped expressions, returns an array of scalar expressions. For scalar expressions, returns the expression unchanged or with recursively scalarized subexpressions.\n\n\n\n\n\n","category":"function"},{"location":"manual/arrays/#SymbolicUtils.shape","page":"Symbolic Arrays","title":"SymbolicUtils.shape","text":"shape(x)\n\nGet the shape of a value or symbolic expression. Generally equivalent to axes for non-symbolic x, but also works on non-array values.\n\n\n\n\n\n","category":"function"},{"location":"manual/limits/#Symbolic-Limits","page":"Symbolic Limits","title":"Symbolic Limits","text":"Experimental symbolic limit support is provided by the limit function, documented below. See SymbolicLimits.jl for more information and implementation details.","category":"section"},{"location":"manual/limits/#SymPy-Integration","page":"Symbolic Limits","title":"SymPy Integration","text":"SymPy also includes limits as well, and the SymPy.jl extensions allow for automatically converting Symbolics expressions for use in its solvers.","category":"section"},{"location":"manual/limits/#Symbolics.limit","page":"Symbolic Limits","title":"Symbolics.limit","text":"limit(expr, var, h[, side::Symbol])\n\nCompute the limit of expr as var approaches h.\n\nside indicates the direction from which var approaches h. It may be one of :left, :right, or :both. If side is :both and the two sides do not align, an error is thrown. Side defaults to :both for finite h, :left for h = Inf, and :right for h = -Inf.\n\nexpr must be composed of log, exp, constants, and the rational operators +, -, *, and /. This limitation may eventually be relaxed.\n\nwarning: Warning\nBecause symbolic limit computation is undecidable, this function necessarily employs heuristics and may occasionally return wrong answers. Nevertheless, please report wrong answers as issues as we aim to have heuristics that produce correct answers in all practical cases.\n\n\n\n\n\n","category":"function"},{"location":"manual/limits/#Symbolics.sympy_limit","page":"Symbolic Limits","title":"Symbolics.sympy_limit","text":"sympy_limit(expr, var, val)\n\nComputes limit of expr as var approaches val using SymPy.\n\nArguments\n\nexpr: Symbolics expression.\nvar: Symbolics variable.\nval: Symbolics expression or number.\n\nReturns\n\nSymbolics limit.\n\nExample\n\n@variables x\nexpr = 1/x\nresult = sympy_limit(expr, x, 0)\n\n\n\n\n\n","category":"function"},{"location":"manual/functions/#function_registration","page":"Function Registration and Tracing","title":"Function Registration and Tracing","text":"Function registration is the ability to define new nodes in the symbolic graph. This is useful because symbolic computing is declarative, i.e. symbolic computations express what should be computed, not how it should be computed. However, at some level someone must describe how a given operation is computed. These are the primitive functions, and a symbolic expression is made up of primitive functions.\n\nSymbolics.jl comes pre-registered with a large set of standard mathematical functions, like * and sin to special functions like erf, and even deeper operations like DataInterpolations.jl's AbstractInterpolation. However, in many cases you may need to add your own function, i.e. you may want to give an imperative code and use this to define a new symbolic code. Symbolics.jl calls the declaration of new declarative primitives from an imperative function definition registration. This page describes both the registration process and its companion process, tracing, for interacting with code written in Julia.","category":"section"},{"location":"manual/functions/#Direct-Tracing","page":"Function Registration and Tracing","title":"Direct Tracing","text":"Because Symbolics expressions respect Julia semantics, one way to generate symbolic expressions is to simply place Symbolics variables as inputs into existing Julia code. For example, the following uses the standard Julia function for the Lorenz equations to generate the symbolic expression for the Lorenz equations:\n\nusing Symbolics\nfunction lorenz(du,u,p,t)\n du[1] = 10.0(u[2]-u[1])\n du[2] = u[1]*(28.0-u[3]) - u[2]\n du[3] = u[1]*u[2] - (8/3)*u[3]\nend\n@variables t p[1:3] u(t)[1:3]\ndu = Array{Any}(undef, 3)\nlorenz(du,u,p,t)\ndu\n\nOr similarly:\n\n@variables t x(t) y(t) z(t) dx(t) dy(t) dz(t) σ ρ β\ndu = [dx,dy,dz]\nu = [x,y,z]\np = [σ,ρ,β]\nlorenz(du,u,p,t)\ndu\n\nNote that what has been done here is that the imperative Julia code for the function lorenz has been transformed into a declarative symbolic graph. Importantly, the code of lorenz is transformed into an expression consisting only of primitive registered functions, things like * and -, which come pre-registered with Symbolics.jl This then allows for symbolic manipulation of the expressions,  allowing things like simplification and operation reordering done on its generated expressions. ","category":"section"},{"location":"manual/functions/#Utility-and-Scope-of-Tracing","page":"Function Registration and Tracing","title":"Utility and Scope of Tracing","text":"This notably describes one limitation of tracing: tracing only  works if the expression being traced is composed of already  registered functions. If unregistered functions, such as calls to C code, are used, then the tracing process will error.\n\nHowever, we note that symbolic tracing by definition does not  guarantee that the exact choices. The symbolic expressions may re-distribute the arithmetic, simplify out expressions, or do other modifications. Thus if this function is function is sensitive to numerical details in its calculation, one would not want to trace the function and thus would instead register it as a new primitive function.\n\nFor the symbolic system to be as powerful in its manipulations as possible, it is recommended that the registration of functions be minimized to the simplest possible set, and thus registration should only be used when necessary. This is because any code within a registered function is treated as a blackbox imperative code that cannot be manipulated, thus decreasing the potential for simplifications.","category":"section"},{"location":"manual/functions/#Registering-Functions","page":"Function Registration and Tracing","title":"Registering Functions","text":"The Symbolics graph only allows registered Julia functions within its type. All other functions are automatically traced down to registered functions. By default, Symbolics.jl pre-registers the common functions utilized in SymbolicUtils.jl and pre-defines their derivatives. However, the user can utilize the @register_symbolic macro to add their function to allowed functions of the computation graph.\n\nAdditionally, @register_array_symbolic can be used to define array functions. For size propagation it's required that a computation of how the sizes are computed is also supplied.","category":"section"},{"location":"manual/functions/#Defining-Derivatives-of-Registered-Functions","page":"Function Registration and Tracing","title":"Defining Derivatives of Registered Functions","text":"In order for symbolic differentiation to work, defining @register_derivative for registered functions is required. For example,\n\n@register_derivative min(x, y) 1 ifelse(x < y, 1, 0)\n\nis the partial derivative of the Julia min(x,y) function with respect to x. Refer to the documentation of @register_derivative for an in-depth explanation of the macro syntax.\n\nQuerying the rules defined using this method requires the use of @derivative_rule.\n\nnote: Note\nDownstream symbolic derivative functionality only work if every partial derivative that is required in the derivative expression is defined. Note that you only need to define the partial derivatives which are actually computed.","category":"section"},{"location":"manual/functions/#Registration-of-Array-Functions","page":"Function Registration and Tracing","title":"Registration of Array Functions","text":"Similar to scalar functions, array functions can be registered to define new primitives for functions which either take in or return arrays. This is done by using the @register_array_symbolic macro. It acts similarly to the scalar function registration but requires a calculation of the input and output sizes. For example, let's assume we wanted to have a function that computes the solution to Ax = b, i.e. a linear solve, using an SVD factorization. In Julia, the code for this would be svdsolve(A,b) = svd(A)\\b. We would create this function as follows:\n\nusing LinearAlgebra, Symbolics\n\nsvdsolve(A, b) = svd(A)\\b\n@register_array_symbolic svdsolve(A::AbstractMatrix, b::AbstractVector) begin\n    size = size(b)\n    eltype = promote_type(eltype(A), eltype(b))\nend\n\nNow using the function svdsolve with symbolic array variables will be kept lazy:\n\n@variables A[1:3, 1:3] b[1:3]\nsvdsolve(A,b)\n\nNote that at this time array derivatives cannot be defined.","category":"section"},{"location":"manual/functions/#Registration-API","page":"Function Registration and Tracing","title":"Registration API","text":"","category":"section"},{"location":"manual/functions/#Direct-Registration-API-(Advanced,-Experimental)","page":"Function Registration and Tracing","title":"Direct Registration API (Advanced, Experimental)","text":"warning: Warning\nThis is a lower level API which is not as stable as the macro APIs.\n\nIn some circumstances you may need to use the direct API in order to define registration on functions or types without using the macro. This is done by directly defining dispatches on symbolic objects.\n\nA good example of this is DataInterpolations.jl's interpolations object. On an interpolation by a symbolic variable, we generate the symbolic function (the term) for the interpolation function. This looks like:\n\nusing DataInterpolations, Symbolics, SymbolicUtils\n(interp::AbstractInterpolation)(t::Num) = SymbolicUtils.term(interp, unwrap(t))\n\nIn order for this to work, it is required that we define the symtype for the symbolic type inference. This is done via:\n\nSymbolicUtils.promote_symtype(t::AbstractInterpolation, args...) = Real\n\nAdditionally a symbolic name is required:\n\nBase.nameof(interp::AbstractInterpolation) = :Interpolation\n\nWith Symbolics.jl v7 we don't expose a direct API for defining derivatives. It requires using the macro.\n\n@register_derivative (interp::AbstractInterpolation)(x) 1 begin\n    # ...\nend","category":"section"},{"location":"manual/functions/#Inverse-function-registration","page":"Function Registration and Tracing","title":"Inverse function registration","text":"Symbolics.jl allows defining and querying the inverses of functions.\n\nSymbolics.jl implements inverses for standard trigonometric and logarithmic functions, as well as their variants from NaNMath. It also implements inverses of ComposedFunctions.","category":"section"},{"location":"manual/functions/#Symbolics.@register_symbolic","page":"Function Registration and Tracing","title":"Symbolics.@register_symbolic","text":"@register_symbolic(expr, define_promotion = true, Ts = [Real])\n\nOverload appropriate methods so that Symbolics can stop tracing into the registered function. If define_promotion is true, then a promotion method in the form of\n\nSymbolicUtils.promote_symtype(::typeof(f_registered), args...) = Real # or the annotated return type\n\nis defined for the register function. Note that when defining multiple register overloads for one function, all the rest of the registers must set define_promotion to false except for the first one, to avoid method overwriting.\n\nExamples\n\n@register_symbolic foo(x, y)\n@register_symbolic foo(x, y::Bool) false # do not overload a duplicate promotion rule\n@register_symbolic goo(x, y::Int) # `y` is not overloaded to take symbolic objects\n@register_symbolic hoo(x, y)::Int # `hoo` returns `Int`\n\nSee @register_array_symbolic to register functions which return arrays.\n\n\n\n\n\n","category":"macro"},{"location":"manual/functions/#Symbolics.@register_array_symbolic","page":"Function Registration and Tracing","title":"Symbolics.@register_array_symbolic","text":"@register_array_symbolic(expr, define_promotion = true)\n\nExample:\n\n# Let's say vandermonde takes an n-vector and returns an n x n matrix\n@register_array_symbolic vandermonde(x::AbstractVector) begin\n    size=(length(x), length(x))\n    eltype=eltype(x) # optional, will default to the promoted eltypes of x\nend\n\nYou can also register calls on callable structs:\n\n@register_array_symbolic (c::Conv)(x::AbstractMatrix) begin\n    size=size(x) .- size(c.kernel) .+ 1\n    eltype=promote_type(eltype(x), eltype(c))\nend\n\nIf define_promotion = true then a promotion method in the form of\n\nSymbolicUtils.promote_symtype(::typeof(f_registered), args...) = # inferred or annotated return type\n\nis defined for the register function. Note that when defining multiple register overloads for one function, all the rest of the registers must set define_promotion to false except for the first one, to avoid method overwriting.\n\n\n\n\n\n","category":"macro"},{"location":"manual/functions/#Symbolics.@register_derivative","page":"Function Registration and Tracing","title":"Symbolics.@register_derivative","text":"@register_derivative fn(args...) Ith_arg derivative\n\nRegister a symbolic derivative for a function. This typically accompanies a call to @register_symbolic or @register_array_symbolic and defines how expand_derivatives will behave when it tries to differentiate the registered function.\n\nThe first argument to the macro is a call to the function whose derivative is being defined. The call cannot have keyword arguments or default arguments. The call must have either an exact number of arguments or a single variadic argument. For example, f(a), f(a, b), f(a, b, c) and f(args...) are valid signatures. f(a, b, args...) is invalid. If an exact number of arguments is provided, the defined derivative is specific to that number of arguments. If the variadic signature is used, the defined derivative is valid for all numbers of arguments. In case multiple derivatives are registered for the same function, they must have different numbers of arguments. A derivative for an exact number of arguments is more specific than a variadic definition. For example, @register_derivatives f(a, b) #... is more specific than @register_derivatives f(args...) #... for a 2-argument call to f. The arguments can be referred to with their declared names inside the derivative definition.\n\nThe second argument to the macro is the argument with respect to which the derivative rule is defined. For example, @register_derivative f(a, b) 2 #... is a derivative rule with respect to the second argument of f. Mathematically, it represents frac partial f(a b)  partial b . To define a generic derivative, this argument can be an identifier. For example, @register_derivative f(a, b) I #... makes I available in the derivative definition as the index of the argument with respect to which the derivative is being taken.\n\nThe third argument to the macro is the derivative expression. This should be a symbolically traceable expression returning the derivative of the specified function with respect to the specified argument. In case of a variadic definition, the identifier Nargs is available to denote the number of arguments provided to the function. In case the variadic form is used, the arguments are available as a read-only array (mutation will error). Mutating the array is unsafe and undefined behavior.\n\nnote: Note\nFor functions that return arrays (such as those registered via @register_array_symbolic) the returned expression must be the Jacobian. Currently, support for differentiating array functions is considered experimental.\n\nwarning: Warning\nThe derivative expression MUST return a symbolic value, or nothing if the derivative is not defined. In case the result is a non-symbolic value, such as a constant derivative or Jacobian of array functions, the result MUST be wrapped in Symbolics.SConst(..).\n\nFollowing are example definitions of derivatives:\n\n@register_derivative sin(x) 1 cos(x)\n@register_derivative max(x, y) 2 ifelse(x >= y, 0, 1)\n@register_derivative min(args...) I begin\n  error(\"The rule for the derivative of `min` with $Nargs arguments w.r.t the $I-th argument is undefined.\")\nend\n@register_derivative (foo::MyCallableStruct)(args...) I begin\n  error(\"Oops! Didn't implement the derivative for $foo\")\nend\n\n\n\n\n\n","category":"macro"},{"location":"manual/functions/#Symbolics.@derivative_rule","page":"Function Registration and Tracing","title":"Symbolics.@derivative_rule","text":"@derivative_rule f(args...) I\n\nQuery Symbolics.jl's derivative rule system for the derivative of f(args...) with respect to args[I]. Returns a symbolic result representing the derivative. In case the derivative rule is not defined, evaluates to nothing.\n\nThe first argument to the macro must be a valid function call syntax. Splatting of arguments is permitted. The second argument must be an expression or literal evaluating to the index of the argument with respect to which the derivative is required.\n\nThe derivative rule can dispatch statically if f, the number of arguments and I are known at compile time. Example invocations are:\n\n# static dispatch\n@derivative_rule sin(x) 1\n# static dispatch if `xs` is a tuple\n@derivative_rule max(xs...) 2\n# static dispatch if `y` and `w` are tuples, and `N + 2K` is a compile-time constant\n@derivative_rule foo(x, y..., z, w...) (N + 2K)\n\n\n\n\n\n","category":"macro"},{"location":"manual/functions/#Symbolics.inverse","page":"Function Registration and Tracing","title":"Symbolics.inverse","text":"inverse(f)\n\nGiven a single-input single-output function f, return its inverse g. This requires that f is bijective. If inverse is defined for a function, left_inverse and right_inverse should return inverse(f). inverse(g) should also be defined to return f.\n\nSee also: left_inverse, right_inverse, @register_inverse.\n\n\n\n\n\n","category":"function"},{"location":"manual/functions/#Symbolics.left_inverse","page":"Function Registration and Tracing","title":"Symbolics.left_inverse","text":"left_inverse(f)\n\nGiven a single-input single-output function f, return its left inverse g. This requires that f is injective. If left_inverse is defined for a function, right_inverse and inverse must not be defined and should error. right_inverse(g) should also be defined to return f.\n\nSee also: inverse, right_inverse, @register_inverse.\n\n\n\n\n\n","category":"function"},{"location":"manual/functions/#Symbolics.right_inverse","page":"Function Registration and Tracing","title":"Symbolics.right_inverse","text":"right_inverse(f)\n\nGiven a single-input single-output function f, return its right inverse g. This requires that f is surjective. If right_inverse is defined for a function, left_inverse and inverse must not be defined and should error. left_inverse(g) should also be defined to return f.\n\nSee also inverse, left_inverse, @register_inverse.\n\n\n\n\n\n","category":"function"},{"location":"manual/functions/#Symbolics.@register_inverse","page":"Function Registration and Tracing","title":"Symbolics.@register_inverse","text":"@register_inverse f g\n@register_inverse f g left\n@register_inverse f g right\n\nMark f and g as inverses of each other. By default, assume that f and g are bijective. Also defines left_inverse and right_inverse to call inverse. If the third argument is left, assume that f is injective and g is its left inverse. If the third argument is right, assume that f is surjective and g is its right inverse.\n\n\n\n\n\n","category":"macro"},{"location":"manual/functions/#Symbolics.has_inverse","page":"Function Registration and Tracing","title":"Symbolics.has_inverse","text":"has_inverse(_) -> Bool\n\n\nCheck if the provided function has an inverse defined via inverse. Uses hasmethod to perform the check.\n\n\n\n\n\n","category":"function"},{"location":"manual/functions/#Symbolics.has_left_inverse","page":"Function Registration and Tracing","title":"Symbolics.has_left_inverse","text":"has_left_inverse(_) -> Bool\n\n\nCheck if the provided function has a left inverse defined via left_inverse Uses hasmethod to perform the check.\n\n\n\n\n\n","category":"function"},{"location":"manual/functions/#Symbolics.has_right_inverse","page":"Function Registration and Tracing","title":"Symbolics.has_right_inverse","text":"has_right_inverse(_) -> Bool\n\n\nCheck if the provided function has a left inverse defined via left_inverse Uses hasmethod to perform the check.\n\n\n\n\n\n","category":"function"},{"location":"getting_started/#Getting-Started-with-Symbolics.jl","page":"Getting Started with Symbolics.jl","title":"Getting Started with Symbolics.jl","text":"Symbolics.jl is a symbolic modeling language. In this tutorial, we will walk you through the process of getting Symbolics.jl up and running, and start doing our first symbolic calculations.","category":"section"},{"location":"getting_started/#Installing-Symbolics.jl","page":"Getting Started with Symbolics.jl","title":"Installing Symbolics.jl","text":"Installing Symbolics.jl is as simple as using the Julia package manager. This is done via the command ]add Symbolics. After precompilation is complete, do using Symbolics in the terminal (REPL) and when that command is completed, you're ready to start!","category":"section"},{"location":"getting_started/#Building-Symbolic-Expressions","page":"Getting Started with Symbolics.jl","title":"Building Symbolic Expressions","text":"The way to define symbolic variables is via the @variables macro:\n\nusing Symbolics\n@variables x y\n\nAfter defining variables as symbolic, symbolic expressions, which we call a iscall object, can be generated by utilizing Julia expressions. For example:\n\nz = x^2 + y\n\nHere, z is an expression tree for “square x and add y”. To make an array of symbolic expressions, simply make an array of symbolic expressions:\n\nA = [x^2 + y 0 2x\n     0       0 2y\n     y^2 + x 0 0]\n\nNote that by default, @variables returns Sym or iscall objects wrapped in Num to make them behave like subtypes of Real. Any operation on these Num objects will return a new Num object, wrapping the result of computing symbolically on the underlying values.\n\nIf you are following this tutorial in the Julia REPL, A will not be shown with LaTeX equations. To get these equations, we can use Latexify.jl. Symbolics.jl comes with Latexify recipes, so it works automatically:\n\nusing Latexify\nlatexify(A)\n\nNormal Julia functions work on Symbolics expressions, so if we want to create the sparse version of A we would just call sparse:\n\nusing SparseArrays\nspA = sparse(A)\nlatexify(A)\n\nWe can thus use normal Julia functions as generators for sparse expressions. For example, here we will define\n\nfunction f(u)\n  [u[1] - u[3], u[1]^2 - u[2], u[3] + u[2]]\nend\nf([x, y, z]) # Recall that z = x^2 + y\n\nOr we can build an array of variables and use it to trace the function:\n\nu = Symbolics.variables(:u, 1:5)\nf(u)\n\nnote: Note\nSymbolics.variables(:u, 1:5) creates a Julia array of symbolic variables. This uses O(n) compute and memory but is a very general representation. Symbolics.jl also has the ability to represent symbolic arrays which gives an O(1) representation but is more limited in its functionality. For more information, see the Symbolic Arrays page.","category":"section"},{"location":"getting_started/#Derivatives","page":"Getting Started with Symbolics.jl","title":"Derivatives","text":"One common thing to compute in a symbolic system is derivatives. In Symbolics.jl, derivatives are represented lazily via operations, just like any other function. To build a differential operator, use Differential like:\n\n@variables t\nD = Differential(t)\n\nThis is the differential operator D = fracpartialpartial t. We can compose the differential operator by *, e.g. Differential(t) * Differential(x) or Differential(t)^2. Now let's write down the derivative of some expression:\n\nz = t + t^2\nD(z)\n\nNotice that this hasn't computed anything yet: D is a lazy operator because it lets us symbolically represent “The derivative of z with respect to t”, which is useful for example when representing our favorite thing in the world, differential equations. However, if we want to expand the derivative operators, we'd use expand_derivatives:\n\nexpand_derivatives(D(z))\n\nThe variable, that you are taking the derivative with respect to, is accessed with:\n\nD.x\n\nWe can also have simplified functions for multivariable calculus. For example, we can compute the Jacobian of an array of expressions like:\n\nSymbolics.jacobian([x + x*y, x^2 + y], [x, y])\n\nand similarly we can do Hessians, gradients, and define whatever other derivatives you want.","category":"section"},{"location":"getting_started/#Simplification-and-Substitution","page":"Getting Started with Symbolics.jl","title":"Simplification and Substitution","text":"Symbolics interfaces with SymbolicUtils.jl to allow for simplifying symbolic expressions. This is done simply through the simplify command:\n\nsimplify(2x + 2y)\n\nThis can be applied to arrays by using Julia's broadcast mechanism:\n\nB = simplify.([t + t^2 + t + t^2  2t + 4t\n               x + y + y + 2t     x^2 - x^2 + y^2])\n\nWe can then use substitute to change values of an expression around:\n\nsimplify.(substitute.(B, (Dict(x => y^2),)))\n\nand we can use this to interactively evaluate expressions without generating and compiling Julia functions:\n\nV = substitute.(B, (Dict(x => 2.0, y => 3.0, t => 4.0),))\n\nWhere we can reference the values via:\n\nSymbolics.value.(V)","category":"section"},{"location":"getting_started/#Non-Interactive-Development","page":"Getting Started with Symbolics.jl","title":"Non-Interactive Development","text":"Note that the macros are for the high-level case where you're doing symbolic computation on your own code. If you want to do symbolic computation on someone else's code, like in a macro, you may not want to do @variables x because you might want the name “x” to come from the user's code. For these cases, you can use the interpolation operator to interpolate the runtime value of x, i.e. @variables $x. Check the documentation of @variables for more details.\n\na, b, c = :runtime_symbol_value, :value_b, :value_c\n\nvars = @variables t $a $b(t) $c(t)[1:3]\n\n(t, a, b, c)\n\nOne could also use variable and variables. Read their documentation for more details.\n\nIf we need to use this to generate new Julia code, we can simply convert the output to an Expr:\n\nSymbolics.toexpr(x + y^2)\n\nThe other way around is also possible, parsing Julia expressions into symbolic expressions\n\nex = [:(v ~ w)\n      :(w ~ -v)]\neqs = parse_expr_to_symbolic.(ex, (Main,))\neqs_lhs = [eq.lhs for eq in eqs]\neqs_rhs = [eq.rhs for eq in eqs]\nSymbolics.jacobian(eqs_rhs, eqs_lhs)","category":"section"},{"location":"getting_started/#Syms-and-callable-Syms","page":"Getting Started with Symbolics.jl","title":"Syms and callable Syms","text":"In the definition\n\n@variables t x(t) y(t)\n\nt is of type Sym{Real}, but the name x refers to an object that represents the Term x(t). The operation of this expression is itself the object Sym{FnType{Tuple{Real}, Real}}(:x). The type Sym{FnType{...}} represents a callable object. In this case specifically, it's a function that takes 1 Real argument (noted by Tuple{Real}) and returns a Real result. You can call such a callable Sym with either a number or a symbolic expression of a permissible type.\n\nThis expression also defines t as an independent variable, while x(t) and y(t) are dependent variables. This is accounted for in differentiation:\n\nz = x + y*t\nexpand_derivatives(D(z))\n\nSince x and y are time-dependent, they are not automatically eliminated from the expression, and thus the D(x) and D(y) operations still exist in the expanded derivatives for correctness.\n\nWe can also define unrestricted functions:\n\n@variables g(..)\n\nHere, g is a variable that is a function of other variables. Any time that we reference g we have to utilize it as a function:\n\nz = g(x) + g(y)","category":"section"},{"location":"getting_started/#Registering-Functions","page":"Getting Started with Symbolics.jl","title":"Registering Functions","text":"One of the benefits of a one-language Julia symbolic stack is that the primitives are all written in Julia, and therefore it's trivially extendable from Julia itself. By default, new functions are traced to the primitives and the symbolic expressions are written on the primitives. However, we can expand the allowed primitives by registering new functions. For example, let's register a new function h:\n\nh(x, y) = x^2 + y\n@register_symbolic h(x, y)\n\nWhen we use h(x, y), it is a symbolic expression and doesn't expand:\n\nh(x, y) + y^2\n\nTo use it with the differentiation system, we need to register its derivatives. We would do it like this:\n\n# Derivative w.r.t. the first argument\nSymbolics.derivative(::typeof(h), args::NTuple{2,Any}, ::Val{1}) = 2args[1]\n# Derivative w.r.t. the second argument\nSymbolics.derivative(::typeof(h), args::NTuple{2,Any}, ::Val{2}) = 1\n\nand now it works with the rest of the system:\n\nSymbolics.derivative(h(x, y) + y^2, x)\n\nSymbolics.derivative(h(x, y) + y^2, y)\n\nnote: Note\n@register_symbolic only allows for scalar outputs. If full array functions are needed, then see @register_array_symbolic for registering functions of symbolic arrays.","category":"section"},{"location":"getting_started/#Building-Functions","page":"Getting Started with Symbolics.jl","title":"Building Functions","text":"The function for building functions from symbolic expressions is the aptly-named build_function. The first argument is the symbolic expression or the array of symbolic expressions to compile, and the trailing arguments are the arguments for the function. For example:\n\nto_compute = [x^2 + y, y^2 + x]\nf_expr = build_function(to_compute, [x, y])\nBase.remove_linenums!.(f_expr)\n\ngives back two codes. The first is a function f([x, y]) that computes and builds an output vector [x^2 + y, y^2 + x]. Because this tool was made to be used by all the cool kids writing fast Julia codes, it is specialized to Julia and supports features like StaticArrays. For example:\n\nusing StaticArrays\nmyf = eval(f_expr[1])\nmyf(SA[2.0, 3.0])\n\nThe second function is an in-place non-allocating mutating function which mutates its first value. Thus, we'd use it like the following:\n\nmyf! = eval(f_expr[2])\nout = zeros(2)\nmyf!(out, [2.0, 3.0])\nout\n\nTo save the symbolic calculations for later, we can take this expression and save it out to a file:\n\nwrite(\"function.jl\", string(f_expr[2]))\n\nNote that if we need to avoid eval, for example to avoid world-age issues, one could do expression = Val{false}:\n\nBase.remove_linenums!(build_function(to_compute, [x, y], expression=Val{false})[1])\n\nwhich will use RuntimeGeneratedFunctions.jl to build Julia functions which avoid world-age issues.","category":"section"},{"location":"getting_started/#Building-Non-Allocating-Parallel-Functions-for-Sparse-Matrices","page":"Getting Started with Symbolics.jl","title":"Building Non-Allocating Parallel Functions for Sparse Matrices","text":"Now let's show off a little bit. build_function is kind of like if lambdify ate its spinach. To show this, let's build a non-allocating function that fills sparse matrices in a multithreaded manner. To do this, we just have to represent the operation that we're turning into a function via a sparse matrix. For example:\n\nusing LinearAlgebra\nN = 8\nA = sparse(Tridiagonal([x^i for i in 1:N-1], [x^i * y^(8-i) for i in 1:N], [y^i for i in 1:N-1]))\nshow(A)\n\nNow we call build_function:\n\nBase.remove_linenums!(build_function(A,[x,y],parallel=Symbolics.MultithreadedForm())[2])\n\nLet's unpack what that's doing. It's using A.nzval to linearly index through the sparse matrix, avoiding the A[i,j] form because that is a more expensive way to index a sparse matrix if you know exactly the order that the data is stored. Then, it's splitting up the calculation into Julia threads, so they can be operated on in parallel. It synchronizes after spawning all the tasks, so the computation is ensured to be complete before moving on. And it does this with all in-place operations to the original matrix instead of generating arrays. This is the fanciest way you could fill a sparse matrix, and Symbolics makes this dead simple.\n\n(Note: this example may be slower with multithreading due to the thread spawning overhead, but the full version was not included in the documentation for brevity. It will be the faster version if N is sufficiently large!)\n\nImportantly, when using the in-place functions generated by build_function, it is important that the mutating argument matches the sparse structure of the original function, as demonstrated below.\n\nusing Symbolics, SparseArrays, LinearAlgebra\n\nN = 10\n_S = sprand(N, N, 0.1)\n_Q = sprand(N, N, 0.1)\n\nF(z) = [ # some complicated sparse amenable function\n    collect(_S * z)\n    collect(_Q * z.^2)\n]\n\nSymbolics.@variables z[1:N]\n\nsj = Symbolics.sparsejacobian(F(z), z) # sparse jacobian\n\nf_expr = build_function(sj, z)\n\nrows, cols, _ = findnz(sj)\nout = sparse(rows, cols, zeros(length(cols)), size(sj)...) # pre-allocate, and correct structure\nmyf = eval(last(f_expr))\nmyf(out, rand(N)) # note that out matches the sparsity structure of sj\nout","category":"section"},{"location":"manual/expression_manipulation/#Expression-Manipulation","page":"Expression Manipulation","title":"Expression Manipulation","text":"Symbolics.jl provides functionality for easily manipulating expressions. Most of the functionality comes by the expression objects obeying the standard mathematical semantics. For example, if one has A a matrix of symbolic expressions wrapped in Num, then A^2 calculates the expressions for the squared matrix.  It is thus encouraged to use standard Julia for performing many of the manipulation on the IR. For example, calculating the sparse form of the matrix via sparse(A) is valid, legible, and easily understandable to all Julia programmers.","category":"section"},{"location":"manual/expression_manipulation/#Functionality-Inherited-From-SymbolicUtils.jl","page":"Expression Manipulation","title":"Functionality Inherited From SymbolicUtils.jl","text":"Documentation for rewriter can be found here, using the @rule macro or the @acrule macro from SymbolicUtils.jl.","category":"section"},{"location":"manual/expression_manipulation/#Functionality-Provided-by-SymPy.jl-Integration","page":"Expression Manipulation","title":"Functionality Provided by SymPy.jl Integration","text":"SymPy also includes solves as well, and the SymPy.jl extensions allow for automatically converting Symbolics expressions for use in its simplifier.","category":"section"},{"location":"manual/expression_manipulation/#Additional-Manipulation-Functions","page":"Expression Manipulation","title":"Additional Manipulation Functions","text":"Other additional manipulation functions are given below.","category":"section"},{"location":"manual/expression_manipulation/#SymbolicUtils.substitute","page":"Expression Manipulation","title":"SymbolicUtils.substitute","text":"substitute(expr, s; fold=Val(true))\n\nPerforms the substitution on expr according to rule(s) s. If fold=Val(false), expressions which can be evaluated won't be evaluated.\n\nwarning: Does not penetrate `Differential`\nAs of Symbolics.jl v7 (SymbolicUtils.jl v4), substitute does not recurse into the arguments of Differential expressions. For example, substitute(D(x), Dict(x => y)) returns D(x), not D(y). Use substitute_in_deriv or substitute_in_deriv_and_depvar to substitute inside Differential applications.\n\nExamples\n\njulia> @variables t x y z(t)\n4-element Vector{Num}:\n    t\n    x\n    y\n z(t)\njulia> ex = x + y + sin(z)\n(x + y) + sin(z(t))\njulia> substitute(ex, Dict([x => z, sin(z) => z^2]))\n(z(t) + y) + (z(t) ^ 2)\njulia> substitute(sqrt(2x), Dict([x => 1]); fold=Val(false))\nsqrt(2)\n\n\n\n\n\n","category":"function"},{"location":"manual/expression_manipulation/#SymbolicUtils.simplify","page":"Expression Manipulation","title":"SymbolicUtils.simplify","text":"simplify(x; expand=false,\n            threaded=false,\n            thread_subtree_cutoff=100,\n            rewriter=nothing)\n\nSimplify an expression (x) by applying rewriter until there are no changes. expand=true applies expand in the beginning of each fixpoint iteration.\n\nBy default, simplify will assume denominators are not zero and allow cancellation in fractions. Pass simplify_fractions=false to prevent this.\n\n\n\n\n\n","category":"function"},{"location":"manual/expression_manipulation/#Symbolics.sympy_simplify","page":"Expression Manipulation","title":"Symbolics.sympy_simplify","text":"sympy_simplify(expr)\n\nSimplifies a Symbolics expression using SymPy.\n\nArguments\n\nexpr: Symbolics expression.\n\nReturns\n\nSimplified Symbolics expression.\n\nExample\n\n@variables x\nexpr = x^2 + 2x^2\nresult = sympy_simplify(expr)\n\n\n\n\n\n","category":"function"},{"location":"manual/expression_manipulation/#Symbolics.get_variables","page":"Expression Manipulation","title":"Symbolics.get_variables","text":"get_variables(e, varlist = nothing; kw...)\n\nReturn a vector of variables appearing in e, optionally restricting to variables in varlist. Takes the same keyword arguments as SymbolicUtils.search_variables.\n\nNote that the returned variables are not wrapped in the Num type.\n\nExamples ≡≡≡≡≡≡≡≡\n\njulia> @variables t x y z(t);\n\njulia> Symbolics.get_variables(x + y + sin(z))\n3-element Vector{SymbolicUtils.BasicSymbolic}:\n x\n y\n z(t)\n\njulia> Symbolics.get_variables(x - y)\n2-element Vector{SymbolicUtils.BasicSymbolic}:\n x\n y\n\n\n\n\n\n","category":"function"},{"location":"manual/expression_manipulation/#Symbolics.tosymbol","page":"Expression Manipulation","title":"Symbolics.tosymbol","text":"tosymbol(x::Union{Num,BasicSymbolic}; states=nothing, escape=true) -> Symbol\n\nConvert x to a symbol. states are the states of a system, and escape means if the target has escapes like val\"y(t)\". If escape is false, then it will only output y instead of y(t).\n\nExamples\n\njulia> @variables t z(t)\n2-element Vector{Num}:\n    t\n z(t)\n\njulia> Symbolics.tosymbol(z)\nSymbol(\"z(t)\")\n\njulia> Symbolics.tosymbol(z; escape=false)\n:z\n\n\n\n\n\n","category":"function"},{"location":"manual/expression_manipulation/#Symbolics.diff2term","page":"Expression Manipulation","title":"Symbolics.diff2term","text":"diff2term(x) -> BasicSymbolic\n\nConvert a differential variable to a Term. Note that it only takes a Term not a Num.\n\njulia> @variables x t u(x, t) z(t)[1:2]; Dt = Differential(t); Dx = Differential(x);\n\njulia> Symbolics.diff2term(Symbolics.value(Dx(Dt(u))))\nuˍtx(x, t)\n\njulia> Symbolics.diff2term(Symbolics.value(Dt(z[1])))\n(zˍt(t))[1]\n\n\n\n\n\n","category":"function"},{"location":"manual/expression_manipulation/#Symbolics.degree","page":"Expression Manipulation","title":"Symbolics.degree","text":"degree(p, sym=nothing)\n\nExtract the degree of p with respect to sym.\n\nExamples\n\njulia> @variables x;\n\njulia> Symbolics.degree(x^0)\n0\n\njulia> Symbolics.degree(x)\n1\n\njulia> Symbolics.degree(x^2)\n2\n\n\n\n\n\n","category":"function"},{"location":"manual/expression_manipulation/#Symbolics.coeff","page":"Expression Manipulation","title":"Symbolics.coeff","text":"coeff(p, sym=nothing)\n\nExtract the coefficient of p with respect to sym. Note that p might need to be expanded and/or simplified with expand and/or simplify.\n\nExamples\n\njulia> @variables a x y;\n\njulia> Symbolics.coeff(2a, x)\n0\n\njulia> Symbolics.coeff(3x + 2y, y)\n2\n\njulia> Symbolics.coeff(x^2 + y, x^2)\n1\n\njulia> Symbolics.coeff(2*x*y + y, x*y)\n2\n\n\n\n\n\n","category":"function"},{"location":"manual/expression_manipulation/#Symbolics.filterchildren","page":"Expression Manipulation","title":"Symbolics.filterchildren","text":"filterchildren(c, x)\n\nReturns all parts of x that fulfills the condition given in c. c can be a function or an expression. If it is a function, returns everything for which the function is true. If c is an expression, returns all expressions that matches it.\n\nExamples:\n\n@syms x\nSymbolics.filterchildren(x, log(x) + x + 1)\n\nreturns [x, x]\n\n@variables t X(t)\nD = Differential(t)\nSymbolics.filterchildren(Symbolics.is_derivative, X + D(X) + D(X^2))\n\nreturns [Differential(t)(X(t)^2), Differential(t)(X(t))]\n\n\n\n\n\n","category":"function"},{"location":"manual/expression_manipulation/#Symbolics.fixpoint_sub","page":"Expression Manipulation","title":"Symbolics.fixpoint_sub","text":"fixpoint_sub(expr, dict, ::Type{OP} = Nothing; maxiters = 1000, filterer = SymbolicUtils.default_substitute_filter)\n\nGiven a symbolic expression, equation or inequality expr perform the substitutions in dict recursively until the expression does not change. Substitutions that depend on one another will thus be recursively expanded. For example, fixpoint_sub(x, Dict(x => y, y => 3)) will return 3. The OP argument can be specified to prevent substitution of expressions inside Operators of the given type. The maxiters keyword is used to limit the number of times the substitution can occur to avoid infinite loops in cases where the substitutions in dict are circular (e.g. [x => y, y => x]).\n\nSee also: FixpointSubstituter.\n\n\n\n\n\n","category":"function"},{"location":"manual/expression_manipulation/#Symbolics.evaluate","page":"Expression Manipulation","title":"Symbolics.evaluate","text":"evaluate(eq::Equation, subs)\nevaluate(ineq::Inequality, subs)\n\nEvaluate the equation eq or inequality ineq. subs is a dictionary of variable to numerical value substitutions.  If both sides of the equation or inequality are numeric, then the result is a boolean. \n\nExamples\n\njulia> @variables x y\njulia> eq = x ~ y\njulia> evaluate(eq, Dict(x => 1, y => 1))\ntrue\n\njulia> ltr = x ≲ y\njulia> evaluate(ltr, Dict(x => 1, y => 2))\ntrue\n\njulia> gtr = x ≳ y\njulia> evaluate(gtr, Dict(x => 1, y => 2))\nfalse\n\n\n\n\n\n","category":"function"},{"location":"manual/expression_manipulation/#Symbolics.symbolic_to_float","page":"Expression Manipulation","title":"Symbolics.symbolic_to_float","text":"symbolic_to_float(x::Union{Num, BasicSymbolic})::Union{AbstractFloat, BasicSymbolic}\n\nIf the symbolic value is exactly equal to a number, converts the symbolic value to a floating point number. Otherwise retains the symbolic value.\n\nExamples\n\nsymbolic_to_float((1//2 * x)/x) # 0.5\nsymbolic_to_float((1/2 * x)/x) # 0.5\nsymbolic_to_float((1//2)*√(279//4)) # 4.175823272122517\n\n\n\n\n\n","category":"function"},{"location":"manual/expression_manipulation/#Symbolics.terms-Tuple{Any}","page":"Expression Manipulation","title":"Symbolics.terms","text":"terms(x)\n\nGet the terms of the symbolic expression x.\n\nExamples\n\njulia> terms(-x + y - z)\n3-element Vector{Num}:\n -z\n  y\n -x\n\n\n\n\n\n","category":"method"},{"location":"manual/expression_manipulation/#Symbolics.factors-Tuple{Any}","page":"Expression Manipulation","title":"Symbolics.factors","text":"factors(x)\n\nGet the factors of the symbolic expression x.\n\nExamples\n\njulia> factors(2 * x * y)\n3-element Vector{Num}:\n 2\n y\n x\n\n\n\n\n\n","category":"method"},{"location":"manual/expression_manipulation/#Base.numerator-Tuple{Union{Num, SymbolicUtils.BasicSymbolicImpl.var\"typeof(BasicSymbolicImpl)\"{T} where T}}","page":"Expression Manipulation","title":"Base.numerator","text":"numerator(x)\n\nReturn the numerator of the symbolic expression x.\n\nExamples\n\njulia> numerator(x/y)\nx\n\n\n\n\n\n","category":"method"},{"location":"manual/expression_manipulation/#Base.denominator-Tuple{Union{Num, SymbolicUtils.BasicSymbolicImpl.var\"typeof(BasicSymbolicImpl)\"{T} where T}}","page":"Expression Manipulation","title":"Base.denominator","text":"denominator(x)\n\nReturn the denominator of the symbolic expression x.\n\nExamples\n\njulia> denominator(x/y)\ny\n\n\n\n\n\n","category":"method"},{"location":"manual/derivatives/#Derivatives-and-Differentials","page":"Derivatives and Differentials","title":"Derivatives and Differentials","text":"A Differential(op) is a partial derivative with respect to op, which can then be applied to some other operations. For example, D=Differential(t) is what would commonly be referred to as d/dt, which can then be applied to other operations using its function call, so D(x+y) is d(x+y)/dt.\n\nBy default, the derivatives are left unexpanded to capture the symbolic representation of the differential equation. If the user would like to expand out all the differentials, the expand_derivatives function eliminates all the differentials down to basic one-variable expressions.\n\nnote: Note\nFor symbolic differentiation, all registered functions in the symbolic expression need a registered derivative. For more information, see the function registration page.","category":"section"},{"location":"manual/derivatives/#High-Level-Differentiation-Functions","page":"Derivatives and Differentials","title":"High-Level Differentiation Functions","text":"The following functions are not exported and thus must be accessed in a namespaced way, i.e. Symbolics.jacobian.","category":"section"},{"location":"manual/derivatives/#Adding-Analytical-Derivatives","page":"Derivatives and Differentials","title":"Adding Analytical Derivatives","text":"There are many derivatives pre-defined by DiffRules.jl. For example,\n\nusing Symbolics\n@variables x y z\nf(x,y,z) = x^2 + sin(x+y) - z\n\nf automatically has the derivatives defined via the tracing mechanism. It will do this by directly building the internals of your function and differentiating that.\n\nHowever, often you may want to define your own derivatives so that way automatic Jacobian etc. calculations can utilize this information. This can allow for more succinct versions of the derivatives to be calculated to scale to larger systems. You can define derivatives for your function via the macro:\n\n@register_derivative my_function(args...) i begin\n    # ...\nend\n\nwhere i means that it's the derivative with respect to the ith argument. args is the array of arguments, so, for example, if your function is f(x,t), then args = [x,t]. You should return an Term for the derivative of your function.\n\nFor example, sin(t)'s derivative (by t) is given by the following:\n\n@register_derivative sin(t) 1 cos(t)\n\nFor more information see @register_derivative.","category":"section"},{"location":"manual/derivatives/#Symbolics.Differential","page":"Derivatives and Differentials","title":"Symbolics.Differential","text":"struct Differential <: SymbolicUtils.Operator\n\nRepresents a differential operator.\n\nFields\n\nx: The variable or expression to differentiate with respect to.\norder: The derivative order. Can be rational for fractional derivatives.\n\nExamples\n\njulia> using Symbolics\n\njulia> @variables x y;\n\njulia> D = Differential(x)\n(D'~x)\n\njulia> D(y) # Differentiate y wrt. x\n(D'~x)(y)\n\njulia> Dx = Differential(x) * Differential(y) # d^2/dxy operator\n(D'~x(t)) ∘ (D'~y(t))\n\njulia> D3 = Differential(x)^3 # 3rd order differential operator\n(D'~x(t)) ∘ (D'~x(t)) ∘ (D'~x(t))\n\n\n\n\n\n","category":"type"},{"location":"manual/derivatives/#Symbolics.expand_derivatives","page":"Derivatives and Differentials","title":"Symbolics.expand_derivatives","text":"expand_derivatives(O; ...)\nexpand_derivatives(O, simplify; throw_no_derivative)\n\n\nExpands derivatives within a symbolic expression O.\n\nThis function recursively traverses a symbolic expression, applying the chain rule and other derivative rules to expand any derivatives it encounters.\n\nArguments\n\nO::BasicSymbolic: The symbolic expression to expand.\nsimplify::Bool=false: Whether to simplify the resulting expression using   SymbolicUtils.simplify.\n\nKeyword Arguments\n\nthrow_no_derivative=false: Whether to throw if a function with unknown  derivative is encountered.\n\nExamples\n\njulia> @variables x y z k;\n\njulia> f = k*(abs(x-y)/y-z)^2\nk*((abs(x - y) / y - z)^2)\n\njulia> Dx = Differential(x) # Differentiate wrt x\n(::Differential) (generic function with 2 methods)\n\njulia> dfx = expand_derivatives(Dx(f))\n(k*((2abs(x - y)) / y - 2z)*ifelse(signbit(x - y), -1, 1)) / y\n\n\n\n\n\n","category":"function"},{"location":"manual/derivatives/#Symbolics.derivative","page":"Derivatives and Differentials","title":"Symbolics.derivative","text":"derivative(O, var; simplify, kwargs...)\n\n\nA helper function for computing the derivative of the expression O with respect to var.\n\nKeyword Arguments\n\nsimplify=false: The simplify argument of expand_derivatives.\n\nAll other keyword arguments are forwarded to expand_derivatives.\n\n\n\n\n\n","category":"function"},{"location":"manual/derivatives/#Symbolics.jacobian","page":"Derivatives and Differentials","title":"Symbolics.jacobian","text":"jacobian(ops, vars; simplify, scalarize, kwargs...)\n\n\nA helper function for computing the Jacobian of an array of expressions with respect to an array of variable expressions.\n\nKeyword Arguments\n\nsimplify=false: The simplify argument of expand_derivatives.\nscalarize=true: Whether to scalarize ops and vars before computing the jacobian.\n\nAll other keyword arguments are forwarded to expand_derivatives.\n\n\n\n\n\n","category":"function"},{"location":"manual/derivatives/#Symbolics.sparsejacobian","page":"Derivatives and Differentials","title":"Symbolics.sparsejacobian","text":"sparsejacobian(ops, vars; simplify, kwargs...)\n\n\nA helper function for computing the sparse Jacobian of an array of expressions with respect to an array of variable expressions.\n\nKeyword Arguments\n\nsimplify=false: The simplify argument of expand_derivatives.\n\nAll other keyword arguments are forwarded to expand_derivatives.\n\n\n\n\n\n","category":"function"},{"location":"manual/derivatives/#Symbolics.sparsejacobian_vals","page":"Derivatives and Differentials","title":"Symbolics.sparsejacobian_vals","text":"sparsejacobian_vals(ops, vars, I, J; simplify, kwargs...)\n\n\nA helper function for computing the values of the sparse Jacobian of an array of expressions with respect to an array of variable expressions given the sparsity structure.\n\nKeyword Arguments\n\nsimplify=false: The simplify argument of expand_derivatives.\n\nAll other keyword arguments are forwarded to expand_derivatives.\n\n\n\n\n\n","category":"function"},{"location":"manual/derivatives/#Symbolics.gradient","page":"Derivatives and Differentials","title":"Symbolics.gradient","text":"gradient(O, vars; simplify, kwargs...)\n\n\nA helper function for computing the gradient of the expression O with respect to an array of variable expressions.\n\nKeyword Arguments\n\nsimplify=false: The simplify argument of expand_derivatives.\n\nAll other keyword arguments are forwarded to expand_derivatives.\n\n\n\n\n\n","category":"function"},{"location":"manual/derivatives/#Symbolics.hessian","page":"Derivatives and Differentials","title":"Symbolics.hessian","text":"hessian(O, vars; simplify, kwargs...)\n\n\nA helper function for computing the Hessian of the expression O with respect to an array of variable expressions.\n\nKeyword Arguments\n\nsimplify=false: The simplify argument of expand_derivatives.\n\nAll other keyword arguments are forwarded to expand_derivatives.\n\n\n\n\n\n","category":"function"},{"location":"manual/derivatives/#Symbolics.sparsehessian","page":"Derivatives and Differentials","title":"Symbolics.sparsehessian","text":"sparsehessian(op, vars; simplify, full, kwargs...)\n\n\nA helper function for computing the sparse Hessian of an expression with respect to an array of variable expressions.\n\nKeyword Arguments\n\nsimplify=false: The simplify argument of expand_derivatives.\nfull=false: Whether to construct the full hessian by also including entries in the upper-triangular half of the matrix.\n\nAll other keyword arguments are forwarded to expand_derivatives.\n\n\n\n\n\n","category":"function"},{"location":"manual/derivatives/#Symbolics.sparsehessian_vals","page":"Derivatives and Differentials","title":"Symbolics.sparsehessian_vals","text":"sparsehessian_vals(op, vars, I, J; simplify, kwargs...)\n\n\nA helper function for computing the values of the sparse Hessian of an expression with respect to an array of variable expressions given the sparsity structure.\n\nKeyword Arguments\n\nsimplify=false: The simplify argument of expand_derivatives.\n\nAll other keyword arguments are forwarded to expand_derivatives.\n\n\n\n\n\n","category":"function"},{"location":"manual/taylor/#Taylor-Series","page":"Taylor Series","title":"Taylor Series","text":"For a real example of how to use the Taylor series functionality, see this tutorial.","category":"section"},{"location":"manual/taylor/#Symbolics.series","page":"Taylor Series","title":"Symbolics.series","text":"series(cs, x, [x0=0,], ns=0:length(cs)-1)\n\nReturn the power series in x around x0 to the powers ns with coefficients cs.\n\nseries(y, x, [x0=0,] ns)\n\nReturn the power series in x around x0 to the powers ns with coefficients automatically created from the variable y.\n\nExamples\n\njulia> @variables x y[0:3] z\n3-element Vector{Any}:\n x\n  y[0:3]\n z\n\njulia> series(y, x, 2)\ny[0] + (-2 + x)*y[1] + ((-2 + x)^2)*y[2] + ((-2 + x)^3)*y[3]\n\njulia> series(z, x, 2, 0:3)\nz[0] + (-2 + x)*z[1] + ((-2 + x)^2)*z[2] + ((-2 + x)^3)*z[3]\n\n\n\n\n\n","category":"function"},{"location":"manual/taylor/#Symbolics.taylor","page":"Taylor Series","title":"Symbolics.taylor","text":"taylor(f, x, [x0=0,] n; rationalize=true, kwargs...)\n\nCalculate the n-th order term(s) in the Taylor series of f around x = x0. If rationalize, float coefficients are approximated as rational numbers (this can produce unexpected results for irrational numbers, for example). Keyword arguments kwargs... are forwarded to internal substitute() calls.\n\nExamples\n\njulia> @variables x\n1-element Vector{Num}:\n x\n\njulia> taylor(exp(x), x, 0:3)\n1 + x + (1//2)*(x^2) + (1//6)*(x^3)\n\njulia> taylor(exp(x), x, 0:3; rationalize=false)\n1.0 + x + 0.5(x^2) + 0.16666666666666666(x^3)\n\njulia> taylor(√(x), x, 1, 0:3)\n1 + (1//2)*(-1 + x) - (1//8)*((-1 + x)^2) + (1//16)*((-1 + x)^3)\n\njulia> isequal(taylor(exp(im*x), x, 0:5), taylor(exp(im*x), x, 0:5))\ntrue\n\n\n\n\n\n","category":"function"},{"location":"manual/taylor/#Symbolics.taylor_coeff","page":"Taylor Series","title":"Symbolics.taylor_coeff","text":"taylor_coeff(f, x[, n]; rationalize=true, kwargs...)\n\nCalculate the n-th order coefficient(s) in the Taylor series of f around x = 0. If rationalize, float coefficients are approximated as rational numbers (this can produce unexpected results for irrational numbers, for example). Keyword arguments kwargs... are forwarded to internal substitute() calls.\n\nExamples\n\njulia> @variables x y\n2-element Vector{Num}:\n x\n y\n\njulia> taylor_coeff(series(y, x, 0:5), x, 0:2:4)\n3-element Vector{Num}:\n y[0]\n y[2]\n y[4]\n\n\n\n\n\n","category":"function"},{"location":"#Symbolics.jl","page":"Home","title":"Symbolics.jl","text":"Symbolics.jl is a fast and modern Computer Algebra System (CAS) for a fast and modern programming language (Julia). The goal is to have a high-performance and parallelized symbolic algebra system that is directly extendable in the same language as that of the users.","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"To install Symbolics.jl, use the Julia package manager:\n\nusing Pkg\nPkg.add(\"Symbolics\")","category":"section"},{"location":"#Citation","page":"Home","title":"Citation","text":"If you use Symbolics.jl, please cite this paper\n\n@article{gowda2021high,\n  title={High-performance symbolic-numerics via multiple dispatch},\n  author={Gowda, Shashi and Ma, Yingbo and Cheli, Alessandro and Gwozdz, Maja and Shah, Viral B and Edelman, Alan and Rackauckas, Christopher},\n  journal={arXiv preprint arXiv:2105.03949},\n  year={2021}\n}","category":"section"},{"location":"#Feature-Summary","page":"Home","title":"Feature Summary","text":"Because Symbolics.jl is built into the Julia language and works with its dispatches, generic functions in Base Julia will work with symbolic expressions! Make matrices of symbolic expressions and multiply them: it will just work. Take the LU-factorization. Etc. Thus, see the Julia Documentation for a large list of functionality available in Symbolics.jl.\n\nA general list of the features is:\n\nSymbolic arithmetic with type information and multiple dispatch\nSymbolic polynomials and trigonometric functions\nPattern matching, simplification and substitution\nDifferentiation\nSymbolic linear algebra (factorizations, inversion, determinants, eigencomputations, etc.)\nDiscrete math (representations of summations, products, binomial coefficients, etc.)\nLogical and Boolean expressions\nSymbolic equation solving and conversion to arbitrary precision\nSupport for non-standard algebras (non-commutative symbols and customizable rulesets)\nSpecial functions (list provided by SpecialFunctions.jl)\nAutomatic conversion of Julia code to symbolic code\nGeneration of (high performance and parallel) functions from symbolic expressions\nFast automated sparsity detection and generation of sparse Jacobians and Hessians\n\nand much more.","category":"section"},{"location":"#Extension-Packages","page":"Home","title":"Extension Packages","text":"Below is a list of known extension packages. If you would like your package to be listed here, feel free to open a pull request!\n\nModelingToolkit.jl: Symbolic representations of common numerical systems\nOrdinary differential equations\nStochastic differential equations\nPartial differential equations\nNonlinear systems\nOptimization problems\nOptimal Control\nCausal and acausal modeling (Simulink/Modelica)\nAutomated model transformation, simplification, and composition\nCatalyst.jl: Symbolic representations of chemical reactions\nSymbolically build and represent large systems of chemical reactions\nGenerate code for ODEs, SDEs, continuous-time Markov Chains, and more\nSimulate the models using the SciML ecosystem with O(1) Gillespie methods\nDataDrivenDiffEq.jl: Automatic identification of equations from data\nAutomated construction of ODEs and DAEs from data\nRepresentations of Koopman operators and Dynamic Mode Decomposition (DMD)\nSymbolicRegression.jl: Distributed High-Performance symbolic regression\nParallelized generic algorithms for finding equations from data\nPareto frontier-based scoring\nReversePropagation.jl: Source-to-source reverse mode automatic differentiation\nAutomated tracing of code and construction of backpropagation equations\nComposes with symbolic transformation and simplification functionality","category":"section"},{"location":"#Reproducibility","page":"Home","title":"Reproducibility","text":"<details><summary>The documentation of this SciML package was built using these direct dependencies,</summary>\n\nusing Pkg # hide\nPkg.status() # hide\n\n</details>\n\n<details><summary>and using this machine and Julia version.</summary>\n\nusing InteractiveUtils # hide\nversioninfo() # hide\n\n</details>\n\n<details><summary>A more complete overview of all dependencies and their versions is also provided.</summary>\n\nusing Pkg # hide\nPkg.status(; mode = PKGMODE_MANIFEST) # hide\n\n</details>\n\nusing TOML\nusing Markdown\nversion = TOML.parse(read(\"../../Project.toml\", String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\", String))[\"name\"]\nlink_manifest = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n                \"/assets/Manifest.toml\"\nlink_project = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n               \"/assets/Project.toml\"\nMarkdown.parse(\"\"\"You can also download the\n[manifest]($link_manifest)\nfile and the\n[project]($link_project)\nfile.\n\"\"\")","category":"section"}]
}
